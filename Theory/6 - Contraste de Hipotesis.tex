\section{Contraste de Hipótesis}

\subsection{Principios básicos de un contraste de hipótesis}

\ejemplo{
    Supongamos que en un laboratorio se está estudiando cierta reacción química sobre una determinada sustancia y que el resultado de dicha reacción es una variable observable que se puede modelizar mediante una v.a. $X$ con distribución normal. \\ \\ Por experiencias anteriores se sabe que, si en la sustancia está presente cierto mineral, $X \sim N(\mu=10, \sigma=4)$ y si no lo está $X \sim N(\mu=11, \sigma=4)$. Se puede comprobar por medio de unos análisis si el mineral está o no presente en la sustancia en estudio, pero dichos análisis son muy costosos, por lo que se procede a realizar la reacción química $n=25$ veces para decidir, a la luz de los resultados, si $\mu=10$ o $\mu=11$.
}

\begin{definición} [Hipótesis Estadística]
Una hipótesis estadística es cualquier afirmación acerca de un modelo estadístico.
\end{definición}


\begin{definición} [Hipótesis Estadística Simple y Compuesta]
    Una hipótesis estadística es simple si especifica totalmente el modelo estadístico, en otro caso, se dice que es compuesta
\end{definición}

\ejemplo{
    Sea $X \sim N(\mu, \sigma^{2}) \implies$
    \begin{enumerate}
        \item $H_0: \mu = 10 \text{ y } \sigma^2 = 4 \rightarrow$ simple 
        \item $H_0: \mu \in [9,11] \text{ y } \sigma^2 = 4 \rightarrow$ compuesta
        \item $H_0: \mu = ? \text{ y } \sigma^2 = 4 \rightarrow$ compuesta
        \item $H_0: \mu \leq 9 \text{ y } \sigma^2 = 4 \rightarrow$ compuesta
    \end{enumerate}
}

\begin{definición} [Hipótesis Estadística Nula y Alternativa]
    Se dice hipótesis nula a la afirmación inicial o por defecto que se pone a prueba. Se asume cierta hasta que haya suficiente evidencia para rechazarla. \\
    En contraste la hipótesis alternativa es la afirmación que se quiere demostrar o detectar. 
\end{definición}

\ejemplo{
    Imagina una fábrica que produce botellas de agua de $1000ml$ de capacidad. Para asegurar la calidad, se toma una muestra aleatoria de las botellas y se mide su contenido. Por tanto nuestro objetivo es verificar si la máquina está llenando correctamente las botellas o si hay un problema. 
    \begin{itemize}
        \item Hipótesis nula: $H_0: \mu = 1000ml$ (la máquina está funcionando correctamente)
        \item Hipótesis alternativa: $H_1: \mu \neq 1000ml$ (la máquina no está funcionando correctamente)
    \end{itemize}
    En este caso concreto sería una prueba \textbf{bilateral} porque nos preocupa tanto si las botellas están con menos como con más de 1 litro. 
}

\begin{definición} [Contraste de Hipótesis Paramétrico]
    Un contraste estadístico es cualquier partición del espacio muestral $\chi^{n}$ en dos subconjutnos $RA$ y $RC$ de tal manera que si el punto muestral $\vec{x} = (x_1, \ldots, x_n)$ pertenece a $RA$ se dice que se acepta la hipótesis nula, es decir, se admite $H_0: \theta \in \Theta_0$ y si $\vec{x} \in RC$ se dice que se rechaza la hipótesis nula o equivalentemente que se acepta la hipótesis alternativa, es decir, se admite $H_1: \theta \in \Theta_1$. \\ 
    A $RA$ se le denomina \textbf{región de aceptación} y a $RC$ se le denomina \textbf{región crítica}. 
\end{definición}

\ejemplo{
    En el primer ejemplo anterior $\Theta=\left\{\mu_{0}, \mu_{1}\right\}, \Theta_{0}=\left\{\mu_{0}\right\}, \Theta_{1}=\left\{\mu_{1}\right\}$
}

\begin{definición}[Estadístico de Contraste]
    En un problema de contraste de hipótesis, se pretende contrastar $H_0$ frente a $H_1$. La decisión ha de basarse en la evidencia aportada por la observación de una muestra o equivalentemente por la observación de un cierto estadístico $T$ denominado \underline{estadístico del contraste} que será usualmente un estimador suficiente del parámetro $\theta$.
\end{definición}

\ejemplo{
    Siguiendo con el ejemplo anterior de la fábrica de botellas, se puede ver que la máquina embotelladora está malfuncionando de dos formas: 
    \begin{itemize}
        \item Tomando una muestra: Supongamos que se toman 3 botellas:
        $$X = (999, 1002, 1005)$$
        Se define una región crítica sobre la muestra completa, por ejemplo: decidimos rechazar $H_0$ si al enos dos botelllas tienen mas de 1003ml  si la mínima es mayor que 500ml. \\
        En este caso en concreto, sólo una tiene mas de 503ml y la minima es menor de 500ml, por tanto no se rechaza la hipótesis nula o $H_0$.
        \item Tomando un estadístico: Tomemos el estadístico media muestral y el ejemplo anterior. En este caso la media muestral es:
        $$\bar{x} = \frac{999 + 1002 + 1005}{3} = 1002$$
        Supongamos que sabemos que en este caso la region crítica es que $\bar{x} > 1003$. En este caso, como $\bar{x} < 1003$, no se rechaza la hipótesis nula o $H_0$.
    \end{itemize}
}

\begin{observación}
    El contraste de hipótesis basado en un estadístico, exige conocer la distribución de dicho estadístico para los posibles valores del parámetro. El contraste se basa en ver si el valor observado del estadístico es raro bajo esa distribución, si ocurre un valor "muy raro" existen dos posibilidades: fue pura casualidad (poco probable) o más probablemente $H_0$ es falsa. 
\end{observación}

\begin{definición} [Región Crítica]
    Sea una partición del espacio muestral $\chi^{n}$ en dos subconjuntos $C$ y $C^{*}$ tales que $\chi^{n}=C \bigcup C^{*}$ y $C \bigcap C^{*}=\phi$. $C$ es una región crítica para el contraste $H_{0}: \theta \in \Theta_{0}$ frente a $H_{1}: \theta \in \Theta_{1}$ sí y sólo sí, se rechaza $H_{0}$ cuando se observa un valor muestral $\left(x_{1}, \cdots, x_{n}\right) \in C$, en cuyo caso se acepta $H_{1}$. 
\end{definición}

\begin{definición} [Región de aceptación]
    Sea una partición del espacio muestral $\chi^{n}$ en dos subconjuntos $C$ y $C^{*}$ tales que $\chi^{n}=C \bigcup C^{*}$ y $C \bigcap C^{*}=\phi$. $C^{*}$ es una región de aceptación para el contraste $H_{0}: \theta \in \Theta_{0}$ frente a $H_{1}: \theta \in \Theta_{1}$ sí y sólo sí, se acepta $H_{0}$ cuando se observa un valor muestral $\left(x_{1}, \cdots, x_{n}\right) \in C^{*}$, en cuyo caso se rechaza $H_{1}$. 
\end{definición}

\begin{observación}
    La región crítica es el equivalente a una \textbf{zona de alarma}. Si nuestros resulatados caen ahí, se activará la alarma y se actúa en consecuencia. La región de aceptación es el equivalente a una \textbf{zona de seguridad}. Si nuestros resultados caen ahí, no se activará la alarma y no se actúa. 
\end{observación}

\ejemplo{
    En el ejemplo anterior de las botellas, si al estimar la media muestral $\bar{x}$, se obtiene un valor de $1003$ o mayor será suficiente para rechazar la hipótesis nula $H_0$ y aceptar la alternativa $H_1$. En este caso, la región crítica sería $\bar{x} \geq 1003$ y la región de aceptación sería $\bar{x} < 1003$.
}

\subsection{Errores de tipo I y de tipo II}
\begin{definición}[Error de tipo I]
    El error de tipo I es el que se comete cuando se rechaza $H_0$ siendo cierta. La probabilidad de cometer un Error de Tipo I se denota por $\alpha$ 
    y se llama nivel de significación del test.
    $$\alpha = \sup_{\theta \in \Theta_0} P_{\theta}(C)$$
\end{definición}

\begin{definición}[Error de tipo II]
    El error de tipo II es el que se comete cuando no se recheza (se acepta) $H_1$ siendo falsa. La probabilidad de cometer un Error de Tipo II se denota por $\beta$.
    $$\beta = \sup_{\theta \in \Theta_1} P_{\theta}(C^c)$$
\end{definición}

\begin{center}
    \begin{tabular}{|l|c|c|}
        \hline
         & \textbf{$H_0$ Verdadera} & \textbf{$H_0$ Falsa} \\
        \hline
        \textbf{Aceptar $H_0$} & No Error & Error Tipo II \\
        \hline
        \textbf{Rechazar $H_0$} & Error Tipo I & No Error \\
        \hline
    \end{tabular}
\end{center}

\ejemplo{
    Imagina que instalas un nuevo sistema de deteccion de incendios en un edificio. El ssistema tiene que decidir constantemente si hay fuego o no.
    \begin{itemize}
        \item Hipótesis Nula ($H_0$): No hay fuego
        \item Hipótesis Alternativa ($H_1$): Hay fuego
    \end{itemize}
    El sistema usa sensores de humo y calor y toma una decisión: Rechazar la hipótesis nula (hay fuego) o no rechazar $H_0$ (no hay fuego). Veamos los dos posibles errores: 
    \begin{enumerate}
        \item Error de tipo I (Falsa alarma): La realidad es que no hay fuego, pero la decisión del sistema es que si lo hay y la alarma suena. Esto puede causar una evacuación innecesaria y gastos en la empresa.
        \item Error de tipo II (Fallo en la detección): Sí hay fuego pero la alarma no suena. Esto puede causar daños graves y poner en peligro la vida de las personas en el edificio.
    \end{enumerate}
}

\ejemplo{
    En el primer ejemplo de todos, las probabilidades de cometer error de tipo I y error de tipo II son $P(\mathrm{I})=P(\bar{x} \geq k \mid \mu=10)$ y $P(\mathrm{II})=P(\bar{x}<k \mid \mu=11)$
}

\begin{observación}
    Lo idóneo sería contar con un test de baja probabilidad de cometer errores tanto de tipo I como de tipo II, pero en la práctica si bajas un error el otro suele subir de forma equilibrida. \\
    La única forma realista de reducir ambos errores simultáneamente sería tomar una muestra más grande, pero ésto conllevaría mas costes, tiempo y recursos. 
\end{observación}

\begin{definición} [Potencia]
    La Potencia de un test es la probabilidad de rechazar correctamente la hipótesis nula ($H_0$) cuando ésta es realmente falsa. Mide la capacidad del test para detectar un efecto o diferencia cuando realmente existe. Se define como $1-\beta$, donde $\beta$ es la probabilidad de cometer un error de tipo II.
\end{definición}

\begin{definición} [Función de Potencia]
    Se define la función potencia del test cómo: 
    $$\beta_{C}(\theta)=P_{\theta}(C)$$
\end{definición}

\ejemplo{
    \begin{itemize}
        \item En el ejemplo anterior, con $n=25$, $C=\{10<\bar{x}<10.006\}$:
        \begin{align*}
            P(\mathrm{I}) &= \beta_{C}(\mu=10) = P(10<\bar{x}<10.006 \mid \mu=10) = 0.05 \\
            P(\mathrm{II}) &= 1-\beta_{C}(\mu=11) = P(10<\bar{x}<10.006 \mid \mu=11) = 0.976
        \end{align*}
    
        \item En el ejemplo anterior, con $n=25$, $C=\{\bar{x} \geq k\}$ y $\alpha=0.05$:
        \begin{align*}
            P(\mathrm{I}) &= \beta_{C}(\mu=10) = P(\bar{x} \geq 11.316 \mid \mu=10) = 0.05 \\
            P(\mathrm{II}) &= 1-\beta_{C}(\mu=11) = P(\bar{x}<11.316 \mid \mu=11) = 0.6554
        \end{align*}
    
        \item En el ejemplo anterior, con $n=100$, $C=\{\bar{x} \geq k\}$ y $\alpha=0.05$:
        \begin{align*}
            P(\mathrm{I}) &= \beta_{C}(\mu=10) = P(\bar{x} \geq 10.658 \mid \mu=10) = 0.05 \\
            P(\mathrm{II}) &= 1-\beta_{C}(\mu=11) = P(\bar{x}<10.658 \mid \mu=11) = 0.196
        \end{align*}
    \end{itemize} 
}

\ejemplo{
    Si para una población $N(\mu, \sigma = 1)$ se quiere contrastar la hipótesis nula $H_0: \mu = 0$ frente a la hipótesis alternativa $H_1: \mu = 3$ con m.a.s. de tamaño $n = 25$ tomando como región crítica $C = \{\bar{X} \geq 0.392\}$, entonces, ésto quiere decir que si calculamos la media de nuestra muestra de 25 observaciones y resulta ser 0.392  más rechazaremos $H_0$ y aceptaremos $H_1$. \\
    Ahora calculemos el nivel de significación $\alpha$, que es la probabilidad de rechazar $H_0$ cuando es cierta, por lo que calcularemos: 
    $$P(\bar{x} \geq 0.392 \mid \mu = 0) = P(N(0, \frac{1}{\sqrt{25}}) \geq 0.392) = P(\frac{\bar{x} - 0}{\frac{1}{5}} \sim Z \geq \frac{0.392 - 0}{\frac{1}{5}}) = P(Z \geq 1.96) = 0.025$$
    La funncion potencia es: 
    $$\beta(\mu) = P(\bar{x} \geq 0.392 \mid \mu) = P(Z \geq \frac{0.392 - \mu}{\frac{1}{5}}) = 1 - \phi(1.96 - 5\mu)$$
    con $Z \sim N(0,1)$ y $\phi$ la función de distribución de la normal estándar.
}



\begin{definición} [p-valor]
    El p-valor es la probabilidad, bajo la hipótesis nula $H_0$ de observar un valor del estadístico de prueba igual o más extremo que el valor observado, es decir,
    $$p(\vec{x}) = P_{\theta_0}(T(\vec{X}) \geq T(\vec{x}))$$
    donde $T(\vec{X})$ es el estadístico de contraste, $\vec{x}$ es la muestra observada y la desigualdad se ajusta dependiendo del tipo de prueba (unilateral a izquierda, deecha o bilateral).
\end{definición}

\begin{observación}
    Los tipos de prueba son:
    \begin{enumerate}
        \item Prueba unilateral a derecha: $\begin{cases} H_0: \mu = \mu_0 \\ H_1: \mu > \mu_0 \end{cases}$
        \item Prueba unilateral a izquierda: $\begin{cases} H_0: \mu = \mu_0 \\ H_1: \mu < \mu_0 \end{cases}$
        \item Prueba bilateral: $\begin{cases} H_0: \mu = \mu_0 \\ H_1: \mu \neq \mu_0 \end{cases}$
    \end{enumerate}
\end{observación}

\ejemplo{
    Sea el contraste de $H_0: \mu = 0$ frente a $H_1: \mu \neq 0$ con una muestra de tamaño $n=25$ y un estadístico de contraste $\bar{X}$. Si se obtiene un valor de $\bar{x} = 0.1$ tal que $X \sim N(\mu, 1)$, el p-valor sería:
    $$p(x_1, \ldots, x_{25}) = P_{\theta_0}(\bar{X} \geq 0.1) = P(N(0, \frac{1}{5}) \geq 0.1) = P(Z \geq 0.5) = 0.69416$$
}


\begin{observación}
    $$\begin{cases}
        \text{Si p-valor}  \leq \alpha \text{ se rechaza } H_0 \\
        \text{Si p-valor}  > \alpha \text{ no se rechaza } H_0
    \end{cases}$$
\end{observación}

<<<<<<< HEAD
=======
\begin{proposición} [Criterio de comparación de contrastes]
Si $C$ y $C^{\prime}$ son dos test con nivel de significación $\alpha$ basados en una muestra $\left(X_{1}, \cdots X_{n}\right)$ de $\left\{F_{\theta}, \theta \in \Theta\right\}$, para contrastar $H_{0}: \theta \in \Theta_{0}$ frente a $H_{1}: \theta \in \Theta_{1}$, tales que $\beta_{C}(\theta) \geq \beta_{C^{\prime}}(\theta), \forall \theta \in \Theta_{1}$, entonces $C$ es uniformemente más potente que $C^{\prime}$    
\end{proposición}



\subsection{Test uniformemente más potente de tamaño $\alpha$}


\begin{proposición}
Sea $C$ una región crítica para el contraste $H_{0}: \theta \in \Theta_{0}$ frente a $H_{1}: \theta \in \Theta_{1}$, basada en una muestra ( $X_{1}, \cdots X_{n}$ ) de $\left\{F_{\theta}, \theta \in \Theta\right\}$ $C$ es un test uniformemente de máxima potencia de tamaño $\alpha$ (TUMP) sí y sólo sí
\begin{enumerate}
\item $\sup \beta_{C}(\theta)=\alpha$ $\theta \in \Theta_{0}$
\item Para cualquier otro test basado en $\left(X_{1}, \cdots X_{n}\right)$ con región crítica $C^{\prime}$ tal que $\sup _{\theta \in \Theta_{0}} \beta_{C^{\prime}}(\theta) \leq \alpha$, es $\beta_{C}(\theta) \geq \beta_{C^{\prime}}(\theta), \forall \theta \in \Theta_{1}$
\end{enumerate}
\end{proposición}

\subsection{Hipótesis nula simple frente a alternativa simple}

\begin{teorema} [Teorema de Neyman-Pearson - Parte I] 
Para contrastar $H_{0}: \theta=\theta_{0}$ frente a $H_{1}: \theta=\theta_{1}$, si para algún $k \geq 0$ existe un test con región crítica $c=\left\{\left(x_{1}, \cdots, x_{n}\right) \in \chi^{n}: \frac{f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)}{f_{\theta_0}\left(x_{1}, \cdots, x_{n}\right)} \geq k\right\}$ y región de aceptación $C^{c}=\left\{\left(x_{1}, \cdots, x_{n}\right) \in x^{n}: \frac{f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)}{f_{\theta_{0}}\left(x_{1}, \cdots x_{n}\right)}<k\right\}$ tal que $\alpha=P_{\theta_{0}}(C)$, entonces $C$ es uniformemente de máxima potencia de tamaño $\alpha$
\end{teorema}

\begin{proof}
Observemos que $C$ es un test de tamaño $\alpha$ ya que $\Theta_{0}=\left\{\theta_{0}\right\}$ y por lo tanto $\sup _{\theta \in \Theta_{0}} \beta_{C}(\theta)=P_{\theta_{0}}(C)=\alpha$\\
Sea $C^{\prime}$ otro test de nivel $\alpha$, es decir tal que $\alpha \geq \sup _{\theta \in \Theta_{0}} \beta_{C^{\prime}}(\theta)=P_{\theta_{0}}\left(C^{\prime}\right)$ y consideremos la siguiente partición del espacio muestral.
$$
\begin{gathered}
S^{+}=\left\{\left(x_{1}, \cdots x_{n}\right) \in \chi^{n}: \mathrm{I}_{C}\left(x_{1}, \cdots x_{n}\right)>\mathrm{I}_{C^{\prime}}\left(x_{1}, \cdots x_{n}\right)\right\}, \\
S^{-}=\left\{\left(x_{1}, \cdots x_{n}\right) \in \chi^{n}: \mathrm{I}_{C}\left(x_{1}, \cdots x_{n}\right)<\mathrm{I}_{C^{\prime}}\left(x_{1}, \cdots x_{n}\right)\right\}, \\
\chi^{n}-S^{+} \bigcup S^{-}=\left\{\left(x_{1}, \cdots x_{n}\right) \in \chi^{n}: \mathrm{I}_{C}\left(x_{1}, \cdots x_{n}\right)=\mathrm{I}_{C^{\prime}}\left(x_{1}, \cdots x_{n}\right)\right\} \\
\int_{\chi^{n}}\left(I_{C}\left(x_{1}, \cdots, x_{n}\right)-I_{C^{\prime}}\left(x_{1}, \cdots, x_{n}\right)\right)\left(f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)-k f_{\theta_{0}}\left(x_{1}, \cdots, x_{n}\right)\right) d x_{1} \cdots d x_{n}= \\
\int_{S^{+}}\left(I_{C}\left(x_{1}, \cdots, x_{n}\right)-I_{C^{\prime}}\left(x_{1}, \cdots, x_{n}\right)\right)\left(f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)-k f_{\theta_{0}}\left(x_{1}, \cdots, x_{n}\right)\right) d x_{1} \cdots d x_{n}+ \\
\int_{S^{-}}\left(I_{C}\left(x_{1}, \cdots, x_{n}\right)-I_{C^{\prime}}\left(x_{1}, \cdots, x_{n}\right)\right)\left(f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)-k f_{\theta_{0}}\left(x_{1}, \cdots, x_{n}\right)\right) d x_{1} \cdots d x_{n}+ \\
\int_{\chi^{n}-S^{+} \cup S^{-}}\left(I_{C}\left(x_{1}, \cdots, x_{n}\right)-I_{C^{\prime}}\left(x_{1}, \cdots, x_{n}\right)\right)\left(f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)-k f_{\theta_{0}}\left(x_{1}, \cdots, x_{n}\right)\right) d x_{1} \cdots d x_{n} \geq 0 \\
\int_{\chi^{n}} I_{C}\left(x_{1}, \cdots, x_{n}\right) f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)-\int_{\chi^{n}} I_{C^{\prime}}\left(x_{1}, \cdots, x_{n}\right) f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right) d x_{1} \cdots d x_{n} \geq \\
k\left(\int_{\chi^{n}} I_{C}\left(x_{1}, \cdots, x_{n}\right) f_{\theta_{0}}\left(x_{1}, \cdots, x_{n}\right)-\int_{\chi^{n}} I_{C^{\prime}}\left(x_{1}, \cdots, x_{n}\right) f_{\theta_{0}}\left(x_{1}, \cdots, x_{n}\right) d x_{1} \cdots d x_{n}\right) \\
P_{\theta_{1}}(C)-P_{\theta_{1}}\left(C^{\prime}\right) \geq k\left(P_{\theta_{0}}(C)-P_{\theta_{0}}\left(C^{\prime}\right)\right) \geq k(\alpha-\alpha)=0 \Rightarrow \beta_{C}(\theta) \geq \beta C^{\prime}(\theta), \forall \theta \in \Theta_{1}=\left\{\theta_{1}\right\}
\end{gathered}
$$
\end{proof}

>>>>>>> cf64b1dbf1a223678e7843b7f55b17f4d1d8f673
\begin{observación}
    En un test, el tamaño de la muestra $n$ y el nivel de significación $\alpha$ se escogen antes de realizar el experimento.
\end{observación}

\begin{observación}
    En la práctica, se da prioridad a no rechazar $H_0$ a la ligera. Solo se rechaza si hay suficiente evidencia en contra. Por eso si no se rechaza $H_0$ no se está diciendo que es verdadera, sino que no hay evidencia suficiente para descartarla. En cambio, si sse rechaza ,se interpreta que hay buena evidencia para aceptar $H_1$. 
\end{observación}

\begin{observación}
    A la hora de diseñar un contraste estadítico se fija de antemano el nivel de significación $\alpha$, a partir de la cual se define la región crítica $C$ (conjunto de dats que te harían rechazar $H_0$). Mientras que el error tipo II emerge después. \\
    Además se pueden dar situaciones excepcionales en las que aunque $\theta$ esté en el espacio paramétrico alternativo $\Theta_1$, el test sea tan poco sensible que su poencia sea baja. En el extremo podría ocurrir que
    $$1 - \beta_C(\theta) \leq \alpha$$
    lo cual significa que la capacidad para rechazar $H_0$ cuando $H_1$ es cierta sería tan mala como el riesgo que te permites de rechazar $H_0$ estando $\theta \in \Theta_0$, es decir, cuando verdaderamente se cumple $H_0$.
\end{observación}

\begin{definición}  [Test más uniformemente potente]
    Dados dos tests con regiones críticas $C$ y $C^{\prime}$ respectivamente, con el mismo nivel de significación para
    $$H_{0}: \theta \in \Theta_{0} \text{ frente a } H_{1}: \theta \in \Theta_{1}$$
    si para todo valor $\theta$ que satisface $H_1$ la potencia del test $C$ es al menos tan grande como la de $C^{\prime}$, es decir:
    $$\beta_{C}(\theta) \geq \beta_{C^{\prime}}(\theta) \forall \quad \theta \in \Theta_1$$  
    entonces decimos que $C$ es uniformemente más potente que $C^{\prime}$, es decir, cuando la probabilidad de que ocurra un error de tipo II es menor para el test $C$ que para el test $C^{\prime}$.
\end{definición}

\begin{definición} [Test Uniformemente de Máxima Potencia]
    Sea $C$ una región crítica para el contraste $H_0: \theta \in \Theta_0$ frente a $H_1: \theta \in \Theta_1$ basada en una muestra $\left(X_{1}, \cdots, X_{n}\right)$ de $\left\{F_{\theta}, \theta \in \Theta\right\}$. $C$ es un test uniformemente de máxima potencia (TUMP) de tamaño $\alpha$ si y sólo si: 
    \begin{enumerate}
        \item $\sup_{\theta \in \Theta_{0}} \beta_{C}(\theta)=\alpha$
        \item Para cualquier otro test basado en $\left(X_{1}, \cdots, X_{n}\right)$ con región crítica $C^{\prime}$ tal que $\sup_{\theta \in \Theta_{0}} \beta_{C^{\prime}}(\theta) \leq \alpha$, es $\beta_{C}(\theta) \geq \beta_{C^{\prime}}(\theta), \forall \theta \in \Theta_{1}$
    \end{enumerate}
\end{definición}


\subsection{Métodos de construcción de hipótesis}

\begin{definición}[Método de construcción de contrastes de hipótesis]
    Es un procedimiento sistemático que te indica cómo elegir o calcular un estadístico de prueba basada en los datos de la muestra y defini una región de rechazo (región crítica) o una regla de decisión (por ejemplo. comparar el p-valor con un nivel de significación $\alpha$). \\
    El objetivo es poder tomar una decisión sobre si rechazar o no la hiótesis nula ($H_0$) basándose en la evidencia de la muestra y hacerlo de forma que se controlen las probabilidades de cometer errores.
\end{definición}

\begin{teorema}[Teorema de Neyman-Pearson Parte I]
    Para contrastar $H_0: \theta \in \Theta_0$ frente a $H_1: \theta \in \Theta_1$ si para algún $k \geq 0$ existe un test con región crítica
    $$C = \left\{ (x_1, \ldots x_n) \in \chi^n : \frac{f_{\theta_1}(x_1, \ldots, x_n)}{f_{\theta_0}(x_1, \ldots. x_n)} \geq k\right\}$$ y región de aceptaión:
    $$C^c = \left\{ (x_1, \ldots x_n) \in \chi^n : \frac{f_{\theta_1}(x_1, \ldots, x_n)}{f_{\theta_0}(x_1, \ldots. x_n)} < k\right\}$$ 
    tales que $\alpha = P_{\theta_0}(C)$, entonces el test relacionado con $C$ es uniformemente de máxima potencia (TUMP).
\end{teorema}

\ejemplo{
    Sea una m.a.s. de tamaño $n$ de una población que sigue una distribución normal $N(\theta, \sigma^2)$ con $\sigma^2$ conocido. Se quiere encontrar el test uniformemente de máxima potencia (TUMP) para contrastar la hipótesis nula $H_0: \theta = \theta_0$ frente a la alternativa $H_1: \theta = \theta_1$, con $\theta_0 < \theta_1$.
    $$\frac{f_{\theta_1}(x_1, \ldots, x_n)}{f_{\theta_0}(x_1, \ldots, x_n)} = \frac{\prod_{i=1}^n \frac{1}{\sqrt{2\pi \sigma^2}} e^{-\frac{(x_i - \theta_1)^2}{2\sigma^2}}}{\prod_{i=1}^n \frac{1}{\sqrt{2\pi \sigma^2}} e^{-\frac{(x_i - \theta_0)^2}{2\sigma^2}}} = \frac{\left(\frac{1}{\sqrt{2\pi\sigma^2}}\right)^n e^{-\frac{1}{2\sigma^2}\sum (x_i - \theta_1)^2}}{\left(\frac{1}{\sqrt{2\pi\sigma^2}}\right)^n e^{-\frac{1}{2\sigma^2}\sum (x_i - \theta_0)^2}} = e^{\frac{1}{2\sigma^2}\sum (x_i - \theta_0)^2 - (x_i - \theta_1)^2} = $$
    $$ = e^{\frac{1}{2\sigma^2}\left(n(\theta_0^2 - \theta_1^2) + 2(\theta_1 - \theta_0)\sum x_i\right)} \implies C = \left\{\vec{x} : e^{\frac{1}{2\sigma^2}\left(n(\theta_0^2 - \theta_1^2) + 2(\theta_1 - \theta_0)\sum x_i\right)} \geq k\right\} \iff$$
    $$ \iff \frac{1}{2\sigma^2}\left(n(\theta_0^2 - \theta_1^2) + 2(\theta_1 - \theta_0)\sum x_i\right) \geq \ln(k) \iff n\bar{x} = \sum x_i \geq c$$ 
    para alguna constante $c$ que depende de $k$, $\theta_0$ y $\theta_1$. 
    $$P_{\theta_0}(C) = P_{\theta_0}\left(\sum x_i \geq c\right) = \alpha \iff P\left(Z \geq \frac{c - n\theta_0}{\sigma\sqrt{n}}\right) = \alpha \iff c = n\theta_0 + \sigma\sqrt{n}z_{1 - \alpha}$$
}


\ejemplo{
    Sea una m.a.s. de tamaño $n$ de una población que sigue una distribución $X \sim Exp(\theta)$ encontrar el TUMP de tamaño $\alpha$ para contrastar $H_0: \theta = \theta_0$ frente a $H_1: \theta = \theta_1$, con $\theta_0 < \theta_1$.
    $$\frac{f_{\theta_1}(x_1, \ldots, x_n)}{f_{\theta_0}(x_1, \ldots, x_n)} = \frac{\prod_{i=1}^n \theta_1 e^{-x_i\theta_1}}{\prod_{i=1}^n \theta_0 e^{-x_i\theta_0}} = \frac{\theta_1^n e^{-\sum x_i\theta_1}}{\theta_0^n e^{-\sum x_i\theta_0}} = \left(\frac{\theta_1}{\theta_0}\right)^n e^{(\theta_0 - \theta_1)\sum x_i} \implies $$
    $$ C = \left\{ \vec{x} \mid \left(\frac{\theta_1}{\theta_0}\right)^n e^{(\theta_0 - \theta_1)\sum x_i} \geq k \right\} = \left\{ \vec{x} \mid n\ln\left(\frac{\theta_1}{\theta_0}\right) + (\theta_0 - \theta_1)\sum x_i \geq \ln(k) \right\} = \left\{ \vec{x} \mid 2\theta_0\sum x_i \leq c \right\} $$
    con $c$ una constante que depende de $k$, $\theta_0$ y $\theta_1$.
    $$P_{\theta_0}(C) = P_{\theta_0}\left(\sum  2\theta_0\sum x_i = \chi_{2n}^2 \leq c\right) = \alpha \iff c = \chi_{2n, \alpha}^2$$
}

\ejemplo{
    Sea una m.a.s. de tamaño $n$ de una población que sigue una distribución $X \sim N(\theta, \sigma^2)$ con $\mu$ conocida. Se quiere encontrar el TUMP de tamaño $\alpha$ para contrastar $H_0: \theta = \theta_0$ frente a $H_1: \theta = \theta_1$, con $\theta_0 < \theta_1$.
    $$\frac{f_{\theta_1}(x_1, \ldots, x_n)}{f_{\theta_0}(x_1, \ldots, x_n)} = \frac{\prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x_i - \theta_1)^2}{2\sigma^2}}}{\prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x_i - \theta_0)^2}{2\sigma^2}}} = \left(\frac{\theta_0}{\theta_1}\right)^n e^{\left(\frac{1}{2\theta_0^2} - \frac{1}{2\theta_1^2}\right)\sum (x_i - \mu)^2} \implies $$
    $$C = \left\{ \vec{x} : \left(\frac{\theta_0}{\theta_1}\right)^n e^{\left(\frac{1}{2\theta_0^2} - \frac{1}{2\theta_1^2}\right)\sum (x_i - \mu)^2} \geq k \right\} 
    = \left\{ \vec{x} : n\ln\left(\frac{\theta_0}{\theta_1}\right) + \left(\frac{1}{2\theta_0^2} - \frac{1}{2\theta_1^2}\right) \sum (x_i - \mu)^2 \geq \ln k \right\} = $$
    $$ = C\left\{\vec{x} : \frac{\sum(x_i  \mu)^2}{\theta_0^2} \geq c\right\}$$
    con $c$ una constante que depende de $k$, $\theta_0$ y $\theta_1$.
    $$P_{\theta_0}(C) = P_{\theta_0}\left(\frac{\sum(x_i - \mu)^2}{\sigma^2} = \chi_{n-1}^2 \geq c\right) = \alpha \iff c = \chi_{n-1, \alpha}^2$$
}

\ejemplo{
    Sea una m.a.s. de tamño $n$ de una población que sigue una distribución $X \sim Bin(1, \theta)$. Se quiere encontrar el TUMP de tamaño $\alpha$ para contrastar $H_0: \theta = \theta_0$ frente a $H_1: \theta = \theta_1$, con $\theta_0 < \theta_1$.
    $$\frac{f_{\theta_1}(x_1, \ldots, x_n)}{f_{\theta_0}(x_1, \ldots, x_n)} = \frac{\prod_{i=1}^n \theta_1^{x_i} (1 - \theta_1)^{(1 - x_i)}}{\prod_{i=1}^n \theta_0^{x_i} (1 - \theta_0)^{(1 - x_i)}} = \left(\frac{\theta_1}{\theta_0}\right)^{\sum x_i} \left(\frac{(1 - \theta_1)}{(1 - \theta_0)}\right)^{n - \sum x_i} = \left(\frac{(1 - \theta_1)}{(1 - \theta_0)}\right)^{n} \cdot \left(\frac{\theta_1}{\theta_0}\frac{1-\theta_0}{1 - \theta_1}\right)^{\sum x_i}$$
    $$\implies C = \left\{ \vec{x} : \left(\frac{(1 - \theta_1)}{(1 - \theta_0)}\right)^{n} \cdot \left(\frac{\theta_1}{\theta_0}\frac{1-\theta_0}{1 - \theta_1}\right)^{\sum x_i} \geq k \right\} = $$ 
    $$= \left\{ \vec{x} : n\ln\left(\frac{(1 - \theta_1)}{(1 - \theta_0)}\right) + \sum x_i \ln\left(\frac{\theta_1}{\theta_0}\frac{1-\theta_0}{1 - \theta_1}\right) \geq \ln k \right\} = \{\vec{x} : \sum x_i \geq c\}$$
    con $c$ una constante que depende de $k$, $\theta_0$ y $\theta_1$.
    $$P_{\theta_0}(C) = P_{\theta_0}\left(\sum x_i \geq c\right) = \alpha = \sum_{i=c}^n \binom{n}{i} \theta_0^i (1 - \theta_0)^{n - i}$$

}

\begin{teorema}[Teorema de Neyman-
    Pearson Parte II]
    Para contrastar $H_0: \theta = \theta_0$ frente a $H_1: \theta = \theta_1$ si para algún $k > 0$ existe un test con región crítica $C$ tal que $P_{\theta_0}(C) = \alpha$ con
    $$\left\{(x_1, \ldots, x_n) \in \chi^n : \frac{f_{\theta_1}(x_1, \ldots, x_n)}{f_{\theta_0}(x_1, \ldots, x_n)} > k \right\} \subset C \subset \left\{(x_1, \ldots, x_n) \in \chi^n : \frac{f_{\theta_1}(x_1, \ldots, x_n)}{f_{\theta_0}(x_1, \ldots, x_n)} \geq k \right\} $$
    entonces cualquier test $C \prime$ uniformemente de máxima potencia de nivel $\alpha$, es de tamaño $\alpha$ y verifica
    $$\left\{(x_1, \ldots, x_n) \in \chi^n : \frac{f_{\theta_1}(x_1, \ldots, x_n)}{f_{\theta_0}(x_1, \ldots, x_n)} > k \right\} \subset C\prime \subset \left\{(x_1, \ldots, x_n) \in \chi^n : \frac{f_{\theta_1}(x_1, \ldots, x_n)}{f_{\theta_0}(x_1, \ldots, x_n)} \geq k \right\} $$
    salvo quizás en un conjunto $A \subset \chi^n$ tal que $P_{\theta_0}(A) = P_{\theta_1}(A)$.
\end{teorema}


\begin{definición}[Test aleatorizado]
    Un test aleatorizado es cualquier función medible tal que $\varphi(\vec{x})$ expresa la probabilidad de rechazar la hipótesis nula $H_0$ para un valor de $\vec{x}$ dado. 
\end{definición}

\begin{definición}[Función de potencia de un test aleatorizado]
    Si $\varphi(\vec{x})$ es un test aleatorizado para el contraste $H_0: \theta \in \Theta_0$ frente a $H_1: \theta \in \Theta_1$, se define la función de potencia del test como:
    $$\beta_{\varphi} : \Theta \to [0,1]$$
    que a cada valor de $\theta$ le asigna el valor $\beta_{\varphi}(\theta) = E_{\theta}[\varphi(\vec{x})]$
\end{definición}

\begin{definición}[Nivel de significación y tamaño de un test aleatorizado]
    Un test aleatorizado $\varphi(\vec{x})$ tiene nivel de significación $\alpha$ si y sólo si $\sup_{\theta \in \Theta_0} \beta_{\varphi}(\theta) \leq \alpha$. y se denomina tamaño del test al valor $\sup_{\theta \in \Theta_0} \beta_{\varphi}(\theta)$.
\end{definición}



\begin{teorema}
    En las mismas condiciones que el teorema de Neyman-Pearson, $\forall \alpha \in (0,1)$ existe un test aleatorizado $\alpha$ de tamaño $\alpha$ de la forma:
    $$\varphi(\vec{x}) = \begin{cases} 1 & \text{ si } \lambda(\vec{x}) < k \\ \gamma  & \text{ si } \lambda(\vec{x}) =  k\\ 0 & \text{ si } \lambda(\vec{x}) > k \end{cases}$$
    donde $k \geq 0$ y $\gamma \in [0,1]$ tales que: 
    $$\alpha = E_{\theta_0}[\varphi(\vec{x})] = P_{\theta_0}\left\{\lambda(\vec{x}) > k \right\} + \gamma P_{\theta_0}\left\{\lambda(\vec{x}) = k \right\}$$
    Además, 
    \begin{enumerate}
        \item $\varphi$ es UMP de tamaño $\alpha$ para contrastar $H_0: \theta = \theta_0$ frente a $H_1: \theta = \theta_1$.
        \item Existe $\varphi$ de la forma del enunciado verificando que $\alpha = E_{\theta_0}[\varphi(\vec{x})]$ para $k > 0$ y $\varphi\prime$ es UMP de nivel $\alpha$, entonces $\varphi\prime$ es de tamaño $\alpha$ y $\varphi\prime = \varphi$ salvo quizás en un conjunto $A \subset \chi^n$ tal que $P_{\theta_0}(A) = P_{\theta_1}(A) = 0$.
    \end{enumerate}
\end{teorema}

\begin{definición}[Test insesgado]
    Un test $\varphi$ de tamaño $\alpha$ para el ocntraste $H_0: \theta \in \Theta_0$ frente a $H_1: \theta \in \Theta_1$ es insesgado si y solo si $E_{\theta_1}[\varphi(\vec{x})] \geq \alpha$ para todo $\theta_1 \in \Theta_1$.
    En otras palabras, el test no puede rechazar la hipótesis nula cuando es cierta.
\end{definición}

\begin{corolario}
    El TUMP de tamaño $\alpha$ construido mediante el teorema de Neyman-Pearson es insesgado. 
\end{corolario}

\ejemplo{
    Para una m.a.s. de tamaño $n$ de una población que sigue una distribución $X \sim Bin(1, \theta)$, se quiere encontrar el TUMP de tamaño $\alpha$ para contrastar $H_0: \theta = \theta_0$ frente a $H_1: \theta = \theta_1$, con $\theta_0 > \theta_1$. Particularizando para $n = 10, \alpha = 0.05, \theta_0 = 0.5$ y $\theta_1 = 0.4$, el test sería: \\
    Para sacar el TUMP apliquemos el teorema de Neyman-Pearson:
    $$\lambda(\vec{x}) = \frac{f_{\theta_1}(x_1, \ldots, x_n)}{f_{\theta_0}(x_1, \ldots, x_n)} = \frac{\prod_{i=1}^n \theta_1^{x_i} (1 - \theta_1)^{(1 - x_i)}}{\prod_{i=1}^n \theta_0^{x_i} (1 - \theta_0)^{(1 - x_i)}} = \left(\frac{\theta_1}{\theta_0}\right)^{\sum x_i} \left(\frac{(1 - \theta_1)}{(1 - \theta_0)}\right)^{n - \sum x_i}$$
    Y por un ejemplo anterior sabemos que la región crítica sería: 
    $$C = \left\{\vec{x} : \sum x_i \geq c \right\} \implies P_{\theta_0}(C) = P_{\theta_0}\left(\sum x_i \geq c\right) = \alpha = \sum_{i=c}^n \binom{n}{i} \theta_0^i (1 - \theta_0)^{n - i}$$
    Ahora sustituyendo tenemos que: 
    $$\lambda(\vec{x}) = \left(\frac{0.4}{0.5}\right)^{\sum x_i} \left(\frac{(1 - 0.4)}{(1 - 0.5)}\right)^{10 - \sum x_i} = \left(\frac{0.8}{0.5}\right)^{\sum x_i} \left(\frac{0.6}{0.5}\right)^{10 - \sum x_i} = \left(\frac{2}{3}\right)^{\sum_{i = 1}^{10} x_i} \left(\frac{6}{5}\right)^{10}$$
    Como las razones son menores que 1, $\lambda(\vec{x})$ decrece con $\sum x_i$, por lo que valores pequeños de $\sum x_i$ rechazamos la hipótesis nula. Además por el lema de Neyman-Pearson, la región crítica es:
    $$C = \left\{\vec{x} : \sum_{i = 1}^{10} x_i \leq c \right\} \text{ tal que } P_{0.5}(C) = P_{0.5}\left(\sum_{i = 1}^{10} x_i \leq c\right) = \alpha = 0.05$$
    Sabiendo que $\sum_{i = 1}^{10} x_i \sim Bin(10, 0.5) \implies P(S = k) = \binom{10}{k} (0.5)^{10}$, podemos obener que $P(\sum_{i = 1}^{10} x_i < 2) = 0.0108$ y $P(\sum_{i = 1}^{10} x_i < 3) = 0.0547$, por lo que el valor crítico sería $c = 2$, y por la teoría vista en clase tenemos que: 
    $$E_{0-5}[\varphi(\vec{x})] = P_{0.5}(S < 2) + \gamma P_{0.5}(S = 2) = 0.0108 + \gamma \cdot 0.2461 = 0.05 \implies \gamma = 0.89$$
}

\begin{definición}[Familia de distribuciones de razón de verosimilitud monótona]
    Una familia de distribuciones $\{f_{\theta}(x) : \theta \in \Theta\}$ sobre un espacio de observación $\chi$ se dice que tiene una razón de verosimilitud monótona (RLVM) en un estadístico suficiente $T(X)$ si para cualquier par de valores $\theta_0, \theta_1 \in \Theta : \theta_0 < \theta_1$. la razón de verosimilitud $$\lambda(x) = \frac{f_{\theta_1}(x)}{f_{\theta_0}(x)}$$ es una función monótona de $T(x)$, es decir, existe una función $g$ tal que $\lambda(x) = g(T(x))$ y $g$ es estrictamente monótona.
\end{definición}

\ejemplo{
    $N(\theta, \sigma)$, con $\sigma$ conocido, pertenece a la famila de distribuciones de razón de verosimilitud monótona, ya que la razón de verosimilitud es:
    $$\lambda(x) = \frac{f_{\theta_1}(x)}{f_{\theta_0}(x)} = \frac{\frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x - \theta_1)^2}{2\sigma^2}}}{\frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x - \theta_0)^2}{2\sigma^2}}} = e^{\frac{(\theta_0 - \theta_1)(\theta_0 + \theta_1 -2x)}{2\sigma^2}} \implies$$ 
    $$\implies \frac{\partial}{\partial x}(\ln(\lambda(x))) = \frac{-2(\theta_0 -\theta_1)}{2\sigma^2} = \frac{\theta_1-\theta_0}{\sigma^2} > 0 \implies \text{crece monótonamente}$$
    Siedo el estadístico $T(X) = X$ un estadístico suficiente para la familia de distribuciones de razón de verosimilitud monótona.
}

\ejemplo{
    Demostremos que la familia exponencial uniparamétrica $f_{\theta}(x) = c(\theta)h(x)e^{q_1(\theta)t_1(x)}$ pertenece a la familia de distribuciones de razón de verosimilitud monótona si $q_1(\theta)$ es monótona: 
    $$\frac{f_{\theta_1}(x)}{f_{\theta_0}(x)} = \frac{c(\theta_1)h(x)e^{q_1(\theta_1)t_1(x)}}{c(\theta_0)h(x)e^{q_1(\theta_0)t_1(x)}} = \frac{c(\theta_1)}{c(\theta_0)} e^{t_1(x)(q_1(\theta_1) - q_1(\theta_0))} \implies$$
    $$\implies \frac{\partial}{\partial x}(\ln(\lambda(x))) = t_1(x)(q_1(\theta_1) - q_1(\theta_0)) > 0 \iff q_1(\theta) \text{es monótona creciente}$$
    Obivamos el término de $c(\theta)$ ya que no depende de la muestra y además es positivo así que no influye en el signo de la derivada. 
}

\ejemplo{
    Sea una m.a.s. de taamaño $n = 1$ de una población que sigue una distribución $X \sim U(0, \theta)$ con $\theta$ desconocido. Demostremos que dicha distribución pertenece a la familia de distribuciones de razón de verosimilitud monótona:
    $$\lambda(x) = \frac{f_{\theta_1}(x)}{f_{\theta_0}(x)} = \frac{\frac{1}{\theta_1}\cdot I_{[0, \theta_0]}(x)}{\frac{1}{\theta_0} \cdot I_{[0, \theta_1]}(x)} = \frac{\theta_0\cdot I_{[0, \theta_1]}(x)}{\theta_1\cdot I_{[0, \theta_0]}(x)} = \begin{cases}
        \text{indefinido} & \text{ si } < 0 \\
        \frac{\theta_0}{\theta_1} & \text{ si } 0 < x < \theta_0 \\
        +\infty & \text{ si } \theta_0 < x < \theta_1 \\
        \text{indefinido} & \text{ si } x > \theta_1 \\
    \end{cases}$$
    Podemos ver que la razón de verosimilitud para los intervalos que nos interesan es creciente en el intervalo $[0, \theta_1]$, por lo tanto pertenece a la familia de distribuciones de razón de verosimilitud monótona. 
}

\begin{teorema}[Teorema de Karlin-Rubin]
    Si $\{F_\theta : \theta \in \Theta\}$ es una familia de distribuciones de razón de verosimilitud monótona creciente en el estadístico $T  = T(X_1, \ldots, X_n)$, entonces: 
    \begin{enumerate}
        \item Para cada $\alpha \in (0,1)$ existe un TUMP de tamaño $\alpha$ para contrastar $H_0: \theta \leq \theta_0$ frente a $H_1: \theta > \theta_0$ de la forma:
        $$\varphi(\vec{x}) = \begin{cases} 1 & \text{ si } T(\vec{x}) > c \\ \gamma & \text{ si } T(\vec{x}) = c \\ 0 & \text{ si } T(\vec{x}) < c \end{cases}$$
        es decir que para cualquier test $\varphi\prime$ tal que $\sup_{\theta \in \Theta_0} \beta_{\varphi\prime}(\theta) \leq \alpha$ (es decir, que controla el error de tipo I) se cumple que $\beta_{\varphi}(\theta) = E_{\theta}[\varphi(\vec{x})] \geq E_{\theta}[\varphi\prime(\vec{x})] = \beta_{\varphi\prime}(\theta) $ para todo $\theta \in \Theta_1$.
        \item Cualquier test $\varphi$ de la forma anterior tiene función de potencia $\beta_{\varphi}(\theta) = E_{\theta}[\varphi(\vec{x})]$ monótona no decreciente. 
    \end{enumerate}
    Una reformulación de las consecuencias del teorema más simple es la siguiente:
    \begin{enumerate}
        \item El test con región crítica $C = \{x : T(x) > c\}$ y con región de aceptación $A = \{x : T(x) \leq c\}$ es el test de máxima potencia para el contraste $H_0: \theta \leq \theta_0$ frente a $H_1: \theta > \theta_0$.
        \item La función de potencia del test dado en el apartado anterior es no decreciente en $\theta$.
    \end{enumerate}
\end{teorema}

\ejemplo{
    Sea una m.a.s. de tamaño $n$ de una población con distribución $X \sim N(\mu, \sigma)$ con $\mu$ conocida. Se quiere encontrar el TUMP de tamaño $\alpha$ para contrastar $H_0: \sigma \leq \sigma_0$ frente a $H_1: \sigma > \sigma_0$: \\
    Para ello haremos uso del Teorema de Karlin-Rubin, para el que necesitamos la razón de verosimilitud:
    $$\Theta_0 = \{\sigma : \sigma \leq \sigma_0\} \quad \Theta_1 = \{\sigma : \sigma > \sigma_0\} \implies \sigma_0 < \sigma_1$$
    $$\lambda(\vec{x}) = \frac{f_{\sigma_1}(x)}{f_{\sigma_0}(x)} = \frac{\prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma_1}} e^{-\frac{(x_i - \mu)^2}{2\sigma_1^2}}}{\prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma_0}} e^{-\frac{(x_i - \mu)^2}{2\sigma_0^2}}} = \left(\frac{\sigma_0}{\sigma_1}\right)^n e^{\sum (x_i - \mu)^2 \left(\frac{1}{2\sigma_0^2} - \frac{1}{2\sigma_1^2}\right)}$$
    Entonces podemos ver que la distribución es monótona creciente en el estadístico $T(X) = \sum (x_i - \mu)^2$, por lo que podemos aplicar el teorema de Karlin-Rubin y obtener así la región crítica del TUMP: 
    $$C = \left\{ \vec{x} : \sum (x_i - \mu)^2 > c \right\} = \left\{\vec{x} : \sum (x_i - \mu)^2 > \chi_{n, 1-\alpha}^2\sigma_0^2 \right\}$$
}

\ejemplo{
    Sea una m.a.s. de tamaño $n$ de una población con distribución $X \sim Exp(\frac{1}{\theta})$ con $\theta$ desconocido. Se quiere encontrar el TUMP de tamaño $\alpha$ para contrastar $H_0: \theta = \theta_0$ frente a $H_1: \theta > \theta_0$: 
    Para ello aplicamos el teorema de Karlin-Rubin, para el que necesitamos la razón de verosimilitud:
    $$\lambda(\vec{x}) = \frac{f_{\theta_1}(x)}{f_{\theta_0}(x)} = \frac{\prod_{i=1}^n \frac{1}{\theta_1} e^{-\frac{x_i}{\theta_1}}}{\prod_{i=1}^n \frac{1}{\theta_0} e^{-\frac{x_i}{\theta_0}}} = \left(\frac{\theta_0}{\theta_1}\right)^n e^{\sum x_i \left(\frac{1}{\theta_0} - \frac{1}{\theta_1}\right)}$$
    Entonces, podemos ver que el cociente de verosimilitud es monótono creciente respecto al estadístico $T(X) = \sum x_i$, por lo que podemos aplicar el teorema de Karlin-Rubin y obtener así la región crítica del TUMP:
    $$X_i \sim Exp(\frac{1}{\theta}) \implies \sum x_i \sim \Gamma(n, \frac{1}{\theta}) \implies C = \left\{ \vec{x} : \sum x_i > c \right\} = \left\{\vec{x} : \sum x_i > \frac{\chi_{2n; 1 - \alpha}^2\theta_0}{2} \right\}$$
}

\begin{definición}[Contraste de la razón de verosimilitudes]
    Para contrastar $H_0: \theta \in \Theta_0$ frente a $H_1: \theta \in \Theta_1$ con una m.a.s. de tamaño $n$ el test de la razón de verosimilitudes (RV) es el que tiene por región crítica $C = \{\vec{x} : \lambda(\vec{x}) \leq k\}$, donde
    $$\lambda(\vec{x}) = \frac{\sup_{\theta \in \Theta_0} L(\theta \mid \vec{x})}{\sup_{\theta \in \Theta} L(\theta \mid \vec{x})}$$
    con $k \in (0,1)$ determinada para que $\sup_{\theta \in \Theta_0} P_{\theta}(C) \leq \alpha$. 
\end{definición}

\ejemplo{
    Sea una población que sigue una distribución $X \sim exp(\theta)$ y se quiere contrastar la hipótesis nula $H_0: \theta = 1$ frente a la alternativa $H_1: \theta \neq 1$. Calculemos el denominador de $\lambda(\vec{x})$, es decir, el Estimador de Máxima Verosimilitud (EMV) de $\theta$:
    $$ f_{\theta}(x) = \theta \cdot e^{-x\theta} \implies L(\vec{x}; \theta) = \theta^n \cdot e^{-\theta \sum x_i} \cdot I_{(0, +\infty)}(X_{(1)}) \implies$$
    $$\implies \log L(\vec{x}; \theta) = n \cdot log(\theta) - \theta \sum x_i \implies \frac{\partial}{\partial \theta} \log L(\vec{x}; \theta) = \frac{n}{\theta} - \sum x_i = 0 \implies$$
    $$\implies \text{ el EMV de } \theta \text{ es } \hat{\theta} = \frac{n}{\sum x_i} = \frac{1}{\bar{X}}$$
    Ahora veamos cómo se describe la región crítica $C$ en este caso: 
    $$C = \left\{ \vec{x} : \frac{L(\theta_0|\vec{x})}{L(\hat{\theta}|\vec{x})} \leq k \right\} 
    = \left\{ \vec{x} : \frac{\theta_0^n e^{-\theta_0 \sum x_i} I_{(0, +\infty)}(X_{(1)})}{\hat{\theta}^n e^{-\hat{\theta} \sum x_i} I_{(0, +\infty)}(X_{(1)})} \leq k \right\} 
    = \left\{ \vec{x} : \frac{\theta_0^n e^{-\theta_0 \sum x_i}}{\left(\frac{n}{\sum x_i}\right)^n e^{-n}} \leq k \right\} = $$
    $$ = \left\{\vec{x} : \left(\frac{\theta_0 e}{n}\right)^n \cdot e^{-\theta_0 \sum x_i} \cdot \left(\sum x_i\right)^n \leq k \right\} = \{\vec{x} : c\left(\sum x_i\right) \leq k\}$$
    Dado que tenemos qe el cociente de verosimilitud depende de $\sum x_i$, podemos redefinir la región crítica para hacerla dependiente de dicho estadístico, pero para ello debemos saber el comportamiento del conjunto, para ello derivaremos: 
    $$\ln\left(c\left(\sum x_i\right)\right) = n\ln(\frac{\theta_0 e}{n}) - \theta_0 \sum x_i + n\ln(\sum x_i) \implies \frac{\partial}{\partial \sum x_i} = -\theta_0 + \frac{n}{\sum x_i} \implies $$
    $$ \implies \frac{\partial^2}{\partial (\sum x_i)^2} = -\frac{n}{(\sum x_i)^2} < 0 \implies \text{ el punto crítico es un máximo } \implies$$ 
    $$ \implies \begin{cases} \text{ si } \sum x_i \leq \frac{n}{\theta_0} \implies c\left(\sum x_i\right) \text{ crece } \\ \text{ si } \sum x_i > \frac{n}{\theta_0} \implies c\left(\sum x_i\right) \text{ decrece } \end{cases}$$
    Por lo tanto, debemos tomar un entorno o umbral del máximo, $A = (c_1, c_2) : c_1 < \frac{n}{\theta_0} < c_2$ y por lo tanto la región crítica $C$ se puede definir como:
    $$C = \left\{ \sum x_i \leq c_1\right\} \cup \left\{\sum x_i \geq c_2 \right\}$$ 
    donde $c$ es una constante que se determina para que el test tenga un nivel de significación $\alpha$. 
}

\ejemplo{
    Para contrastar $H_0: \theta \leq \theta_0$ frente a $H_1: \theta > \theta_0$ con una m.a.s. de tamaño $n$ y $X \sim Bernoulli(\theta)$, mediante el test de la razón de verosimilitudes, se tiene que:
    $$\lambda(\vec{x}) = \frac{\sup_{\theta \in \Theta_0} \theta^{\sum x_i}(1 - \theta)^{n - \sum x_i}}{\sup_{\theta \in \Theta} \theta^{\sum x_i}(1 - \theta)^{n - \sum x_i}} = \frac{\sup_{\theta \leq \theta_0} \theta^{\sum x_i}(1 - \theta)^{n - \sum x_i}}{\sup_{\theta \in [0.1]} \theta^{\sum x_i}(1 - \theta)^{n - \sum x_i}}$$
    Dado que el denominador busca maximizar en todo el espacio paramétrico, estamos tratando con el Estimador de Máxima Verosimilitud (EMV) de $\theta$ que en el caso de las Bernoullis es $\hat{\theta} = \bar{X}$. Entonces hemos de tratar dos situaciones en relación a $\theta_0$:
    \begin{enumerate}
        \item Caso 1: $$\bar{x} \leq \theta_0 \implies \bar{x} \in \Theta_0 \implies \lambda(\vec{x}) = \frac{L(\bar{x}) \mid \vec{x}}{L(\bar{x}) \mid \vec{x}} = 1$$
        \item Caso 2: $$\bar{x} > \theta_0 \implies \bar{x} \not\in \Theta_0 \implies \lambda(\vec{x}) = \frac{L(\theta_0) \mid \vec{x}}{L(\bar{x}) \mid \vec{x}} = \frac{\theta_0^{\sum x_i}(1 - \theta_0)^{n - \sum x_i}}{\bar{x}^{\sum x_i}(1 - \bar{x})^{n - \sum x_i}}$$
    \end{enumerate}
    Dado que $\theta_0$ es un valor fijo, podemos fijarnos en el segundo caso, que a medida que aumente $\bar{x}$, la razón de verosimilitud $\lambda(\vec{x})$ decrece. Ésto es equivalente a decir que a medida que aumenta $\bar{x}$, los datos se hacen menos verosímiles o equivalentemente a medida que aumente $\bar{x}$ la evidencia en contra de $H_0$ (y a favor de $H_1$) se hace más fuerte. Por lo tanto, la región crítica $C$ se puede definir como $C = \{\vec{x} : \bar{x} \geq c\}$ para una constante $c$ y tal que $P(\bar{x} \geq c \mid H_0) \leq \alpha$. 
}


\ejemplo{
    Sea una m.a.s. de tamaño $n$ de una población con distribución $X \sim N(\mu, \sigma)$ con $\sigma$ conocido. Se quiere construir el test de la razón de verosimilitudes para contrastar $H_0: \theta = \theta_0$ frente a $H_1: \theta \neq \theta_0$:
    $$\Delta(\vec{x}) = \frac{\sup_{\theta \in \Theta_0} L(\theta \mid \vec{x})}{\sup_{\theta \in \Theta} L(\theta \mid \vec{x})} = e^{\frac{1}{2\sigma^2} \left(\sum (x_i - \theta_0)^2 + (x_i - \theta_1)^2\right)} = \frac{\left(\frac{1}{\sqrt{2\pi\sigma^2}}\right)^n e^{-\frac{1}{2\sigma^2} \left(\sum (x_i - \theta_0)^2\right)}}{\left(\frac{1}{\sqrt{2\pi\sigma^2}}\right)^n e^{-\frac{1}{2\sigma^2} \left(\sum (x_i - \bar{x})^2\right)}} = e^{-\frac{n(\bar{x} - \theta_0^2)}{2\sigma^2}} \implies$$
    Por el contraste de la razón de verosimilitudes, la region crítica $C$ se puede definir como:
    $$C = \left\{\vec{x} : e^{-\frac{n(\bar{x} - \theta_0)^2}{\sigma^2}} \geq k \right\} = \left\{\vec{x} : \frac{-n(\bar{x} - \theta_0)^2}{\sigma^2} \geq \ln(k)\right\} = \left\{\vec{x} : (\bar{x} - \theta_0)^2 \geq \frac{\ln(k)\sigma^2}{n}\right\} = $$ $$ = \left\{\vec{x} : \bar{x} - \theta_0 \geq \mp \sqrt{\frac{\ln(k)\sigma^2}{n}} \right\} = \left\{\vec{x} : \left| \frac{\bar{x} - \theta_0}{\sigma^2} \right| = Z \sim N(0,1) \geq c \right\} \implies c = z_{\alpha/2}$$
}

\ejemplo{
    Sea una m.a.s. de tamaño $n$ de una población con distribución $X \sim N(\mu, \sigma)$ con $\mu$ conocida, asumimos que $\sigma^2 = \theta^2$. Se quiere construir el test de la razón de verosimilitudes para contrastar $H_0: \theta = \theta_0$ frente a $H_1: \theta \neq \theta_0$:
    $$\Delta(\vec{x}) = \frac{\sup_{\theta \in \Theta_0} L(\theta \mid \vec{x})}{\sup_{\theta \in \Theta} L(\theta \mid \vec{x})} = \frac{\left(\frac{1}{\sqrt{2\pi\theta_0^2}}\right)^n e^{-\frac{1}{2\theta_0^2} \left(\sum (x_i - \mu)^2\right)}}{\left(\frac{1}{\sqrt{2\pi S_{\mu}^2}}\right)^n e^{-\frac{1}{2 S_{\mu}^2} \left(\sum (x_i - \mu)^2\right)}} = \left(\frac{S_\mu^2}{\theta_0^2}\right)^{\frac{n}{2}} e^{\frac{n}{2} \left(1 - \frac{S_{\mu}^2}{\theta_0^2}\right)} = c(S_\mu^2) \implies$$
    $$\implies \frac{\partial}{\partial \sum (x_i - \mu)^2}(\ln(\Delta(\vec{x}))) = \frac{1}{2 S_{\mu}^2} - \frac{1}{2\theta_0^2} \implies \begin{cases}
        \text{ si } S_{\mu}^2 < \theta_0^2 \implies \Delta(\vec{x}) \text{ crece } \\
        \text{ si } S_{\mu}^2 > \theta_0^2 \implies \Delta(\vec{x}) \text{ decrece } \\
    \end{cases} \implies$$
    Por tanto existe un umbral $(c_1, c_2)$ tal que $c_1 < \theta_0 < c_2$ y la región crítica $C$ se puede definir como:
    $$C = \left\{ \vec{x} : S_{\mu}^2 < c_1 \right\} \cup \left\{ \vec{x} : S_{\mu}^2 > c_2 \right\}$$
    Sabemos que $\frac{n S_{\mu}^2}{\theta_0^2} \sim \chi_n^2$ y por lo tanto la región crítica se puede definir como:
    $$C = \left\{ \vec{x} : \frac{n S_{\mu}^2}{\theta_0^2} \sim \chi_n^2 < \frac{n c_1}{\theta_0^2} \right\} \cup \left\{ \vec{x} : \frac{n S_{\mu}^2}{\theta_0^2} \sim \chi_n^2 > \frac{n c_2}{\theta_0^2} \right\} \iff \begin{cases}
        c_1 = \frac{\theta_0^2}{n} \chi_{n, \alpha/2}^2 \\
        c_2 = \frac{\theta_0^2}{n} \chi_{n, 1 - \alpha/2}^2
    \end{cases}$$
}

\begin{comment} NO SÉ A QUÉ PERTENECIA ESTE EJEMPLO

\ejemplo{

Para una muestra de tamaño $n=12$, extraída de una distribución de Poisson con parámetro $\theta$, donde $\theta \in [0, 0.5]$, se plantea el siguiente contraste de hipótesis:

\[
\begin{cases}
H_{0}: \theta = 0 \\
H_{1}: \theta = 0.5
\end{cases}
\]

La región crítica para este contraste viene dada por:
\[
C = \{(x_1, \ldots, x_{12}) : \sum_{i=1}^{12} x_i \geq 2 \}
\]

En este caso particular, como $\sum_{i=1}^{12} x_i < 2$, se tiene que $\overline{X} < \frac{1}{6}$.

La probabilidad de error de tipo I ($\alpha$) y la función de potencia ($\beta(\theta)$) se calculan como sigue:

\begin{align*}
\alpha &= \beta(0) = P\left(C \mid \theta=0\right) = P\left(\sum_{i=1}^{12} x_i \geq 2 \mid \theta=0\right) = 0 \\
\beta(0.5) &= P\left(C \mid \theta=0.5\right) = P\left(\sum_{i=1}^{12} x_i \geq 2 \mid \theta=0.5\right) \\
&= P\left(\text{Poisson}(6) \geq 2\right) \\
&= 1 - P\left(\text{Poisson}(6) = 0\right) - P\left(\text{Poisson}(6) = 1\right) \\
&= 1 - e^{-6}\left(\frac{6^0}{0!} + \frac{6^1}{1!}\right) \\
&= 1 - e^{-6}(1 + 6) \approx 0.9826 \\
\beta(0.25) &= P\left(C \mid \theta=0.25\right) = P\left(\sum_{i=1}^{12} x_i \geq 2 \mid \theta=0.25\right) \\
&= P\left(\text{Poisson}(3) \geq 2\right) \\
&= 1 - P\left(\text{Poisson}(3) = 0\right) - P\left(\text{Poisson}(3) = 1\right) \\
&= 1 - e^{-3}\left(\frac{3^0}{0!} + \frac{3^1}{1!}\right) \\
&= 1 - e^{-3}(1 + 3) \approx 0.8009
\end{align*}

}
\end{comment}

\begin{teorema}
    $\Theta_0 = \{\theta \in \Theta : \theta_i = g_(\vec{\omega}), \vec{\omega} \in \Omega, i = 1, \ldots, k\}$ siendo $\Omega \subset \mathbb{R}^q$ y $g_i$ funciones de clase $C^1$, entonces si se verifican ciertas condiciones de regularidad:
    \begin{enumerate}
        \item El soporte de la distribución no depende de $\theta$.
        \item $\ln(f_\theta(x))$ es declase $C^2$ en $\theta$ y $\forall \vec{x}$
        \item $I_1(\theta) \in (0, \infty)$ 
        \item Los operadores derivada e integral son interacambiables
    \end{enumerate}
     para cada $\theta \in \Theta_0$ se cumple que: 
    $$-2 \ln \Delta (x_1, \dots, x_n) \xrightarrow[n \to \infty]{d} \chi^2_{k-q}$$
\end{teorema}


\subsection{Contrastes bayesianos}

\begin{definición}[Probabilidad final de la hipótesis nula y alternativa y region crítica]
    $$P(\Theta_0 | \vec{x}) = \int_{\Theta_0} \pi(\theta | \vec{x}) d\theta \quad \quad P(\Theta_1 | \vec{x}) = \int_{\Theta_1} \pi(\theta | \vec{x}) d\theta$$
    Por tanto la región crítica es:
    $$C = \{\vec{x} : P(\theta \in \Theta_1 | \vec{x}) > P(\theta \in \Theta_0 | \vec{x}) \}$$
\end{definición}

\ejemplo{
    Para contrastar $H_0: \theta = \theta_0$ frente a $H_1: \theta = \theta_1$ tales que $\theta_1 > \theta_0$ con una m.a.s. de tamaño $n$ y $X \sim N(\mu, \sigma)$ con $\sigma$ conocido si la distribución inicial viene dada por $\pi(\theta) = p$ veamos cual es la región crítica: \\
    Dado que la distribución inicial es discreta, tenemos que:  
    $$P(\Theta_0 | \vec{x}) = \pi(\theta_0 | \vec{x}) = \frac{L(\theta_0 | \vec{x})p}{pL(\theta_0 | \vec{x}) + (1 - p)L(\theta_1 | \vec{x})}$$
    $$P(\Theta_1 | \vec{x}) = \pi(\theta_1 | \vec{x}) = \frac{L(\theta_1 | \vec{x})(1 - p)}{pL(\theta_0 | \vec{x}) + (1 - p)L(\theta_1 | \vec{x})}$$
    $$\implies C = \left\{ \frac{L(\theta_1 | \vec{x})(1 - p)}{pL(\theta_0 | \vec{x}) + (1 - p)L(\theta_1 | \vec{x})} > \frac{L(\theta_0 | \vec{x})p}{pL(\theta_0 | \vec{x}) + (1 - p)L(\theta_1 | \vec{x})}\right\} = \left\{\frac{L(\theta_1 | \vec{x})}{L(\theta_0 | \vec{x})} > \frac{p}{1 - p}\right\} = $$
    $$ = \left\{e^{\frac{1}{2\sigma^2}n(\theta_1 - \theta_0)(2\bar{x} - \theta_0 - \theta_1)} > \frac{p}{1-p}\right\} = \left\{\frac{n}{2\sigma^2}(\theta_1 - \theta_0)(2\bar{x} - \theta_0 - \theta_1) > \ln\left(\frac{p}{1-p}\right)\right\} = $$
    $$ =  \left\{\bar{x} > \frac{(\ln(p) - \ln(1 - p))\sigma^2}{n(\theta_1-\theta_0)} + \frac{\theta_0}{2} + \frac{\theta_1}{2}\right\}$$
}

\begin{definición}[Factor Bayes]
    Para contrastar $H_0: \theta \in \Theta_0$ frente a $H_1: \theta \in \Theta_1$ se define el factor bayes como:
    $$BF(\vec{x}, H_0, H_1) = \frac{\frac{P(\Theta_0 \mid \vec{x})}{P(\Theta_1 \mid \vec{x})}}{\frac{P(\Theta_0)}{P(\Theta_1)}}$$
    donde $h_0$ es la hipótesis nula y $H_1$ la alternativa. El factor bayes mide la fuerza de la evidencia a favor de $H_0$ frente a $H_1$. Si $BF > 1$ se dice que hay evidencia a favor de $H_0$, si $BF < 1$ se dice que hay evidencia a favor de $H_1$ y si $BF = 1$ no hay evidencia a favor de ninguna de las dos hipótesis.
\end{definición}

\ejemplo{
    Sea una m.a.s. de tamaño $n$ de una población con distribución $X \sim Bin(1, \theta)$ para contrastar $H_0: \theta = \frac{1}{2}$ frente a $H_1: \theta = \frac{2}{3}$, calculemos el Factor Bayes a favor de $H_0$ y particularicemos para $n = 10$ y se observan $2, 5$ y $8$ éxitos:
    $$BF(\vec{x}, H_0, H_1) = \frac{\frac{P(\theta = \frac{1}{2} \mid \vec{x})}{P(\theta = \frac{2}{3} \mid \vec{x})}}{\frac{\frac{1}{2}}{\frac{1}{2}}} = \frac{\frac{1}{2}^{\sum x_i} (1 - \frac{1}{2})^{n - \sum x_i}}{\frac{2}{3}^{\sum x_i} (1 - \frac{2}{3})^{n - \sum x_i}} = \frac{\frac{1}{2}^n}{\frac{2}{3}^{\sum x_i} (\frac{1}{3})^{n - \sum x_i}} = \left(\frac{3}{2}\right)^n \left(\frac{1}{2}\right)^{\sum x_i}$$
    Ahora particularicemos para $n = 10$ y $\sum x_i = 2, 5, 8$:
    \begin{enumerate}
        \item Para $\sum x_i = 2$: $$BF(\vec{x}, H_0, H_1) = \left(\frac{3}{2}\right)^{10} \left(\frac{1}{2}\right)^{2} \approx 14.4162$$
        \item Para $\sum x_i = 5$: $$BF(\vec{x}, H_0, H_1) = \left(\frac{3}{2}\right)^{10} \left(\frac{1}{2}\right)^{5} \approx 1.8020$$
        \item Para $\sum x_i = 8$: $$BF(\vec{x}, H_0, H_1) = \left(\frac{3}{2}\right)^{10} \left(\frac{1}{2}\right)^{8} \approx 0.2252$$
    \end{enumerate}
}

\ejemplo{
    Sea una m.a.s. de tamaño $n$ de una poblacion $N(\theta, \sigma)$ con $\sigma$ conocida. se pretende contrastar $H_0: \theta = 0$ frente a $H_1: \theta \neq 0$. Si se supone que la información inicial asigna probabilidad $p$ a la hipótesis nula y reparte la restante, $1 - p$ con densidad $N(0, \sigma_0)$ con $\sigma_0$ conocida, calculemos el factor bayesiano:
$$
f(\vec{x}\mid 0)
=
\Bigl(\tfrac{1}{\sigma\sqrt{2\pi}}\Bigr)^n
\exp\!\Bigl(-\tfrac{1}{2\sigma^2}\sum_{i=1}^n x_i^2\Bigr)
$$    $$
\int_{\Theta} f(\vec{x}\mid \theta)\,\pi(\theta)\,d\theta
=
\int_{\Theta}
\Bigl(\tfrac{1}{\sigma\sqrt{2\pi}}\Bigr)^n
\exp\!\Bigl(-\tfrac{1}{2\sigma^2}\sum_{i=1}^n (x_i - \theta)^2\Bigr)
\;\cdot\;
\tfrac{1}{\sigma_0\sqrt{2\pi}}
\exp\!\Bigl(-\tfrac{1}{2\sigma_0^2}\,\theta^2\Bigr)
\,d\theta
$$
    Desarrollando llegamos a que: 
$$
C
=
\Bigl\{
\sqrt{1 + n\,\tfrac{\sigma_0^2}{\sigma^2}}\;
\exp\!\Bigl(-\tfrac{1}{2}\,n^2\,\tfrac{\bar{x}^2}{\sigma^2}\,
\tfrac{\sigma_0^2}{\sigma^2 + n\,\sigma_0^2}\Bigr)
<
\tfrac{1 - p}{p}
\Bigr\}
$$
}


\begin{comment} NO SÉ DE DÓNDE SON ESTOS EJEMPLOS SI LO SABEIS RESOLVEDLOS Y PONEDLOS EN SU SITIO
\ejemplo{
Para una m.a.s.(n) de $X \sim N(\theta, \sigma)$, con $\sigma$ conocida, encontrar el TUMP de tamaño $\alpha$ para contrastar $H_{0}: \theta=\theta_{0}$ frente a $H_{1}: \theta=\theta_{1}$, con $\theta_{0}<\theta_{1}$\\
$\frac{f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)}{f_{\theta_0}\left(x_{1}, \cdots x_{n}\right)}=e^{\frac{1}{\sigma^{2}} n\left(\theta_{0}^{2}-\theta_{1}^{2}\right)} e^{\frac{1}{\sigma^{n} n} n\left(\theta_{1}-\theta_{0}\right)} \geq k \Leftrightarrow \bar{x} \geq c$\\
donde $c$ es tal que $P_{\theta_{0}}\{\bar{x} \geq c\}=\alpha$, es decir $c=\theta_{0}+z_{\alpha} \frac{\sigma}{\sqrt{n}}$
}

\ejemplo{
Para una m.a.s.(n) de $X \sim \operatorname{Exp}(\theta)$, encontrar el TUMP de tamaño $\alpha$ para contrastar $H_{0}: \theta=\theta_{0}$ frente a $H_{1}: \theta=\theta_{1}$, con $\theta_{0}<\theta_{1}$\\
$\frac{f_{\theta_1}\left(x_{1}, \cdots, x_{n}\right)}{f_{\theta_{0}}\left(x_{1}, \cdots x_{n}\right)}=\left(\frac{\theta_{1}}{\theta_{0}}\right)^{n} e^{\left(\theta_{0}-\theta_{1}\right) \sum_{i=1}^{n} x_{i}} \geq k \Leftrightarrow 2 \theta_{0} \sum_{i=1}^{n} x_{i} \leq c$\\
donde $c$ es tal que $P_{\theta_{0}}\left\{2 \theta_{0} \sum_{i=1}^{n} x_{i} \leq c\right\}=\alpha$, es decir $c=\chi_{2 n, \alpha}^{2}$
}

\ejemplo{
Para una m.a.s.(n) de $X \sim N(\mu, \theta)$, con $\mu$ conocida, encontrar el TUMP de tamaño $\alpha$ para contrastar $H_{0}: \theta=\theta_{0}$ frente a $H_{1}: \theta=\theta_{1}$, con $\theta_{0}<\theta_{1}$\\
$\frac{f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)}{f_{\theta_{0}}\left(x_{1}, \cdots x_{n}\right)}=\left(\frac{\theta_{0}}{\theta_{1}}\right)^{n} e^{\frac{1}{2}\left(\frac{1}{\theta_{0}^{2}}-\frac{1}{\theta_{1}^{2}}\right) \sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}} \geq k \Leftrightarrow \frac{\sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}}{\theta_{0}^{2}} \geq c$ donde $c$ es tal que $P_{\theta_{0}}\left\{\frac{\sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}}{\theta_{0}^{2}} \geq c\right\}=\alpha$, es decir $c=\chi_{n, \alpha}^{2}$
}

\ejemplo{
Para una m.a.s.(n) de $X \sim \operatorname{Bin}(1, \theta)$, encontrar el TUMP de tamaño $\alpha$ para contrastar $H_{0}: \theta=\theta_{0}$ frente a $H_{1}: \theta=\theta_{1}$, con $\theta_{0}<\theta_{1}$\\
$\frac{f_{\theta_1}\left(x_{1}, \cdots, x_{n}\right)}{f_{\theta_{0}}\left(x_{1}, \cdots x_{n}\right)}=\left(\frac{1-\theta_{1}}{1-\theta_{0}}\right)^{n}\left(\frac{\theta_{1}}{\theta_{0}} \frac{1-\theta_{0}}{1-\theta_{1}}\right)^{\sum_{i=1}^{n} x_{i}} \Leftrightarrow \sum_{i=1}^{n} x_{i} \geq c$\\
donde $c$ es tal que $P_{\theta_{0}}\left\{\sum_{i=1}^{n} x_{i} \geq c\right\}=\sum_{j=c}^{n}\binom{n}{j} \theta_{0}^{j}\left(1-\theta_{0}\right)^{n-j}=\alpha_{c}, c=0,1,2, \ldots, n$
}



\section*{Contrastes de hipótesis unilaterales}
Familia de distribuciones de razón de verosimilitud monótona Sea $X \approx\left(\chi, \beta_{\chi}, F_{\theta}\right)_{\theta \in \Theta \subset \mathbb{R}}$ un modelo estadístico continuo (o discreto) uniparamétrico y $\left(X_{1}, \cdots, X_{n}\right)$ una muestra de $\left\{F_{\theta}, \theta \in \Theta\right\}$, siendo $f_{\theta}\left(x_{1}, \cdots x_{n}\right)$ su función de densidad (o de masa) $\left\{F_{\theta}, \theta \in \Theta\right\}$ es una familia de distribuciones de razón de verosimilitud monótona creciente (o decreciente) sí y sólo sí existe un estadístico $T=T\left(X_{1}, \cdots, X_{n}\right): \chi^{n} \rightarrow \mathbb{R}$ tal que, si $\theta_{0}, \theta_{1} \in \Theta$ y $\theta_{0}<\theta_{1}$, entonces la razón de verosimilitudes $\frac{f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)}{f_{\theta_{0}}\left(x_{1}, \cdots, x_{n}\right)}$ es una función monótona creciente (o decreciente) en $T\left(x_{1}, \cdots, x_{n}\right)$


\ejemplo{
    Sea $X \sim exp(\theta)$ vamos a comparar la hipótesis nula $H_0: \theta = \theta_0$ frente a la alternativa $H_1: \theta = \theta_1$, tales que $\theta_0 < \theta_1$. Sea el test $\varphi$: 
    $$\varphi(\vec{x}) = \begin{cases}
        1 & \text{si } \vec{x} \in C^\circ, \\
        a & \text{si } \vec{x} \in \partial C, \\
        0 & \text{si } \vec{x} \in C^c
    \end{cases}$$
    Recordemos además la definición matemática de región crítica: 
    $$C = \left\{(x_1, \ldots, x_n) = \vec{x} \in \chi^n : \frac{\sup_{\theta \in H_1} f_{\theta}(\vec{x})}{\sup_{\theta \in H_0} f_{\theta}(\vec{x})} \geq k\right\}$$
    equivalentemente podríamos haber escrito que el valor de $\theta \in \Theta_0$ tal que $f_{\theta}(\vec{x})$ alcance el supremo en $\theta_0$ es el valor crítico $k$ y también podríamos haber escrito que el valor de $\theta \in \Theta_1$ tal que $f_{\theta}(\vec{x})$ alcance el supremo en $\theta_1$ es el valor crítico $k$. Por lo tanto, la región crítica se puede escribir como:
    $$C = \left\{\vec{x} : \frac{f_{\theta_1}(\vec{x})}{f_{\theta_0}(\vec{x})} \geq k \right\} = \left\{\vec{x} : \frac{(\theta_1)^n \cdot e^{-\theta_1 \sum_{i=1}^n x_i} \cdot I_{(0, +\infty)}(X_{(1)})}{(\theta_0)^n \cdot e^{-\theta_0 \sum_{i=1}^n x_i} \cdot I_{(0, +\infty)}(X_{(1)})} \geq k \right\}.$$
}
\end{comment}