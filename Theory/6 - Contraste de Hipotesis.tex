\section{Contraste de Hipótesis}

\subsection{Principios básicos de un contraste de hipótesis}

\ejemplo{
    Supongamos que en un laboratorio se está estudiando cierta reacción química sobre una determinada sustancia y que el resultado de dicha reacción es una variable observable que se puede modelizar mediante una v.a. $X$ con distribución normal. \\ \\ Por experiencias anteriores se sabe que, si en la sustancia está presente cierto mineral, $X \sim N(\mu=10, \sigma=4)$ y si no lo está $X \sim N(\mu=11, \sigma=4)$. Se puede comprobar por medio de unos análisis si el mineral está o no presente en la sustancia en estudio, pero dichos análisis son muy costosos, por lo que se procede a realizar la reacción química $n=25$ veces para decidir, a la luz de los resultados, si $\mu=10$ o $\mu=11$.
}

\begin{definición} [Hiptótesis Estadística]
Una hipótesis estadística es cualquier afirmación acerca de un modelo estadístico.
\end{definición}


\begin{definición} [Hipótesis Estadística Simple y Compuesta]
    Una hipótesis estadística es simple si especifica totalmente el modelo estadístico, en otro caso, se dice que es compuesta
\end{definición}

\ejemplo{
    Sea $X \sim N(\mu, \sigma^{2}) \implies$
    \begin{enumerate}
        \item $H_0: \mu = 10 \text{ y } \sigma^2 = 4 \rightarrow$ simple 
        \item $H_0: \mu \in [9,11] \text{ y } \sigma^2 = 4 \rightarrow$ compuesta
        \item $H_0: \mu = ? \text{ y } \sigma^2 = 4 \rightarrow$ compuesta
        \item $H_0: \mu \leq 9 \text{ y } \sigma^2 = 4 \rightarrow$ compuesta
    \end{enumerate}
}

\begin{definición} [Hipótesis Estadística Nula y Alternativa]
    Se dice hipótesis nula a la afirmación inicial o por defecto que se pone a prueba. Se asume cierta hasta que haya suficiente evidencia para rechazarla. \\
    En contraste la hipótesis alternativa es la afirmación que se quiere demostrar o detectar. 
\end{definición}

\ejemplo{
    Imagina una fábrica que produce botellas de agua de $1000ml$ de capacidad. Para asegurar la calidad, se toma una muestra aleatoria de las botellas y se mide su contenido. Por tanto nuestro objetivo es verificar si la máquina está llenando correctamente las botellas o si hay un problema. 
    \begin{itemize}
        \item Hipótesis nula: $H_0: \mu = 1000ml$ (la máquina está funcionando correctamente)
        \item Hipótesis alternativa: $H_1: \mu \neq 1000ml$ (la máquina no está funcionando correctamente)
    \end{itemize}
    En este caso concreto sería una prueba \textbf{bilateral} porque nos preocupa tanto si las botellas están con menos como con más de 1 litro. 
}

\begin{definición} [Contraste de Hipótesis Paramétrico]
    Un contraste estadístico es cualquier partición del espacio muestral $\chi^{n}$ en dos subconjutnos $RA$ y $RC$ de tal manera que si el punto muestral $\vec{x} = (x_1, \ldots, x_n)$ pertenece a $RA$ se dice que se acepta la hipótesis nula, es decir, se admite $H_0: \theta \in \Theta_0$ y si $\vec{x} \in RC$ se dice que se rechaza la hipótesis nula o equivalentemente que se acepta la hipótesis alternativa, es decir, se admite $H_1: \theta \in \Theta_1$. \\ 
    A $RA$ se le denomina \textbf{región de aceptación} y a $RC$ se le denomina \textbf{región crítica}. 
\end{definición}

\ejemplo{
    En el primer ejemplo anterior $\Theta=\left\{\mu_{0}, \mu_{1}\right\}, \Theta_{0}=\left\{\mu_{0}\right\}, \Theta_{1}=\left\{\mu_{1}\right\}$
}

\begin{definición}[Estadístico de Contraste]
    En un problema de contraste de hipótesis, se pretende contrastar $H_0$ frente a $H_1$. La decisión ha de basarse en la evidencia aportada por la observación de una muestra o equivalentemente por la observación de un cierto estadístico $T$ denominado \underline{estadístico del contraste} que será usualmente un estimador suficiente del parámetro $\theta$.
\end{definición}

\ejemplo{
    Siguiendo con el ejemplo anterior de la fábrica de botellas, se puede ver que la máquina embotelladora está malfuncionando de dos formas: 
    \begin{itemize}
        \item Tomando una muestra: Supongamos que se toman 3 botellas:
        $$X = (999, 1002, 1005)$$
        Se define una región crítica sobre la muestra completa, por ejemplo: decidimos rechazar $H_0$ si al enos dos botelllas tienen mas de 1003ml  si la mínima es mayor que 500ml. \\
        En este caso en concreto, sólo una tiene mas de 503ml y la minima es menor de 500ml, por tanto no se rechaza la hipótesis nula o $H_0$.
        \item Tomando un estadístico: Tomemos el estadístico media muestral y el ejemplo anterior. En este caso la media muestral es:
        $$\bar{x} = \frac{999 + 1002 + 1005}{3} = 1002$$
        Supongamos que sabemos que en este caso la region crítica es que $\bar{x} > 1003$. En este caso, como $\bar{x} < 1003$, no se rechaza la hipótesis nula o $H_0$.
    \end{itemize}
}

\begin{observación}
    El contraste de hipótesis basado en un estadístico, exige conocer la distribución de dicho estadístico para los posibles valores del parámetro. El contraste se basa en ver si el valor observado del estadístico es raro bajo esa distribución, si ocurre un valor "muy raro" existen dos posibilidades: fue pura casualidad (poco probable) o más probablemente $H_0$ es falsa. 
\end{observación}

\begin{definición} [Región Crítica]
    Sea una partición del espacio muestral $\chi^{n}$ en dos subconjuntos $C$ y $C^{*}$ tales que $\chi^{n}=C \bigcup C^{*}$ y $C \bigcap C^{*}=\phi$. $C$ es una región crítica para el contraste $H_{0}: \theta \in \Theta_{0}$ frente a $H_{1}: \theta \in \Theta_{1}$ sí y sólo sí, se rechaza $H_{0}$ cuando se observa un valor muestral $\left(x_{1}, \cdots, x_{n}\right) \in C$, en cuyo caso se acepta $H_{1}$. 
\end{definición}

\begin{definición} [Región de aceptación]
    Sea una partición del espacio muestral $\chi^{n}$ en dos subconjuntos $C$ y $C^{*}$ tales que $\chi^{n}=C \bigcup C^{*}$ y $C \bigcap C^{*}=\phi$. $C^{*}$ es una región de aceptación para el contraste $H_{0}: \theta \in \Theta_{0}$ frente a $H_{1}: \theta \in \Theta_{1}$ sí y sólo sí, se acepta $H_{0}$ cuando se observa un valor muestral $\left(x_{1}, \cdots, x_{n}\right) \in C^{*}$, en cuyo caso se rechaza $H_{1}$. 
\end{definición}

\begin{observación}
    La región crítica es el equivalente a una \textbf{zona de alarma}. Si nuestros resulatados caen ahí, se activará la alarma y se actúa en consecuencia. La región de aceptación es el equivalente a una \textbf{zona de seguridad}. Si nuestros resultados caen ahí, no se activará la alarma y no se actúa. 
\end{observación}

\ejemplo{
    En el ejemplo anterior de las botellas, si al estimar la media muestral $\bar{x}$, se obtiene un valor de $1003$ o mayor será suficiente para rechazar la hipótesis nula $H_0$ y aceptar la alternativa $H_1$. En este caso, la región crítica sería $\bar{x} \geq 1003$ y la región de aceptación sería $\bar{x} < 1003$.
}

\subsection{Errores de tipo I y de tipo II}
\begin{definición}[Error de tipo I]
    El error de tipo I es el que se comete cuando se rechaza $H_0$ siendo cierta. La probabilidad de cometer un Error de Tipo I se denota por $\alpha$ 
    y se llama nivel de significación del test.
    $$\alpha = \sup_{\theta \in \Theta_0} P_{\theta}(C)$$
\end{definición}

\begin{definición}[Error de tipo II]
    El error de tipo II es el que se comete cuando no se recheza (se acepta) $H_1$ siendo falsa. La probabilidad de cometer un Error de Tipo II se denota por $\beta$.
    $$\beta = \sup_{\theta \in \Theta_1} P_{\theta}(C^c)$$
\end{definición}

\begin{center}
    \begin{tabular}{|l|c|c|}
        \hline
         & \textbf{$H_0$ Verdadera} & \textbf{$H_0$ Falsa} \\
        \hline
        \textbf{Aceptar $H_0$} & No Error & Error Tipo II \\
        \hline
        \textbf{Rechazar $H_0$} & Error Tipo I & No Error \\
        \hline
    \end{tabular}
\end{center}

\ejemplo{
    Imagina que instalas un nuevo sistema de deteccion de incendios en un edificio. El ssistema tiene que decidir constantemente si hay fuego o no.
    \begin{itemize}
        \item Hipótesis Nula ($H_0$): No hay fuego
        \item Hipótesis Alternativa ($H_1$): Hay fuego
    \end{itemize}
    El sistema usa sensores de humo y calor y toma una decisión: Rechazar la hipótesis nula (hay fuego) o no rechazar $H_0$ (no hay fuego). Veamos los dos posibles errores: 
    \begin{enumerate}
        \item Error de tipo I (Falsa alarma): La realidad es que no hay fuego, pero la decisión del sistema es que si lo hay y la alarma suena. Esto puede causar una evacuación innecesaria y gastos en la empresa.
        \item Error de tipo II (Fallo en la detección): Sí hay fuego pero la alarma no suena. Esto puede causar daños graves y poner en peligro la vida de las personas en el edificio.
    \end{enumerate}
}

\ejemplo{
    En el primer ejemplo de todos, las probabilidades de cometer error de tipo I y error de tipo II son $P(\mathrm{I})=P(\bar{x} \geq k \mid \mu=10)$ y $P(\mathrm{II})=P(\bar{x}<k \mid \mu=11)$
}

\begin{observación}
    Lo idóneo sería contar con un test de baja probabilidad de cometer errores tanto de tipo I como de tipo II, pero en la práctica si bajas un error el otro suele subir de forma equilibrida. \\
    La única forma realista de reducir ambos errores simultáneamente sería tomar una muestra más grande, pero ésto conllevaría mas costes, tiempo y recursos. 
\end{observación}

\begin{definición} [Potencia]
    La Potencia de un test es la probabilidad de rechazar correctamente la hipótesis nula ($H_0$) cuando ésta es realmente falsa. Mide la capacidad del test para detectar un efecto o diferencia cuando realmente existe. Se define como $1-\beta$, donde $\beta$ es la probabilidad de cometer un error de tipo II.
\end{definición}

\begin{definición} [Función de Potencia]
    Se define la función potencia del test cómo: 
    $$\beta_{C}(\theta)=P_{\theta}(C)$$
\end{definición}

\ejemplo{
    \begin{itemize}
        \item En el ejemplo anterior, con $n=25$, $C=\{10<\bar{x}<10.006\}$:
        \begin{align*}
            P(\mathrm{I}) &= \beta_{C}(\mu=10) = P(10<\bar{x}<10.006 \mid \mu=10) = 0.05 \\
            P(\mathrm{II}) &= 1-\beta_{C}(\mu=11) = P(10<\bar{x}<10.006 \mid \mu=11) = 0.976
        \end{align*}
    
        \item En el ejemplo anterior, con $n=25$, $C=\{\bar{x} \geq k\}$ y $\alpha=0.05$:
        \begin{align*}
            P(\mathrm{I}) &= \beta_{C}(\mu=10) = P(\bar{x} \geq 11.316 \mid \mu=10) = 0.05 \\
            P(\mathrm{II}) &= 1-\beta_{C}(\mu=11) = P(\bar{x}<11.316 \mid \mu=11) = 0.6554
        \end{align*}
    
        \item En el ejemplo anterior, con $n=100$, $C=\{\bar{x} \geq k\}$ y $\alpha=0.05$:
        \begin{align*}
            P(\mathrm{I}) &= \beta_{C}(\mu=10) = P(\bar{x} \geq 10.658 \mid \mu=10) = 0.05 \\
            P(\mathrm{II}) &= 1-\beta_{C}(\mu=11) = P(\bar{x}<10.658 \mid \mu=11) = 0.196
        \end{align*}
    \end{itemize} 
}

\ejemplo{
    Si para una población $N(\mu, \sigma = 1)$ se quiere contrastar la hipótesis nula $H_0: \mu = 0$ frente a la hipótesis alternativa $H_1: \mu = 3$ con m.a.s. de tamaño $n = 25$ tomando como región crítica $C = \{\bar{X} \geq 0.392\}$, entonces, ésto quiere decir que si calculamos la media de nuestra muestra de 25 observaciones y resulta ser 0.392  más rechazaremos $H_0$ y aceptaremos $H_1$. \\
    Ahora calculemos el nivel de significación $\alpha$, que es la probabilidad de rechazar $H_0$ cuando es cierta, por lo que calcularemos: 
    $$P(\bar{x} \geq 0.392 \mid \mu = 0) = P(N(0, \frac{1}{\sqrt{25}}) \geq 0.392) = P(\frac{\bar{x} - 0}{\frac{1}{5}} \sim Z \geq \frac{0.392 - 0}{\frac{1}{5}}) = P(Z \geq 1.96) = 0.025$$
    La funncion potencia es: 
    $$\beta(\mu) = P(\bar{x} \geq 0.392 \mid \mu) = P(Z \geq \frac{0.392 - \mu}{\frac{1}{5}}) = 1 - \phi(1.96 - 5\mu)$$
    con $Z \sim N(0,1)$ y $\phi$ la función de distribución de la normal estándar.
}



\begin{definición} [p-valor]
    El p-valor es la probabilidad, bajo la hipótesis nula $H_0$ de observar un valor del estadístico de prueba igual o más extremo que el valor observado, es decir,
    $$p(\vec{x}) = P_{\theta_0}(T(\vec{X}) \geq T(\vec{x}))$$
    donde $T(\vec{X})$ es el estadístico de contraste, $\vec{x}$ es la muestra observada y la desigualdad se ajusta dependiendo del tipo de prueba (unilateral a izquierda, deecha o bilateral).
\end{definición}

\begin{observación}
    Los tipos de prueba son:
    \begin{enumerate}
        \item Prueba unilateral a derecha: $\begin{cases} H_0: \mu = \mu_0 \\ H_1: \mu > \mu_0 \end{cases}$
        \item Prueba unilateral a izquierda: $\begin{cases} H_0: \mu = \mu_0 \\ H_1: \mu < \mu_0 \end{cases}$
        \item Prueba bilateral: $\begin{cases} H_0: \mu = \mu_0 \\ H_1: \mu \neq \mu_0 \end{cases}$
    \end{enumerate}
\end{observación}

\ejemplo{
    Sea el contraste de $H_0: \mu = 0$ frente a $H_1: \mu \neq 0$ con una muestra de tamaño $n=25$ y un estadístico de contraste $\bar{X}$. Si se obtiene un valor de $\bar{x} = 0.1$ tal que $X \sim N(\mu, 1)$, el p-valor sería:
    $$p(x_1, \ldots, x_{25}) = P_{\theta_0}(\bar{X} \geq 0.1) = P(N(0, \frac{1}{5}) \geq 0.1) = P(Z \geq 0.5) = 0.69416$$
}


\begin{observación}
    $$\begin{cases}
        \text{Si p-valor}  \leq \alpha \text{ se rechaza } H_0 \\
        \text{Si p-valor}  > \alpha \text{ no se rechaza } H_0
    \end{cases}$$
\end{observación}

\begin{observación}
    En un test, el tamaño de la muestra $n$ y el nivel de significación $\alpha$ se escogen antes de realizar el experimento.
\end{observación}

\begin{observación}
    En la práctica, se da prioridad a no rechazar $H_0$ a la ligera. Solo se rechaza si hay suficiente evidencia en contra. Por eso si no se rechaza $H_0$ no se está diciendo que es verdadera, sino que no hay evidencia suficiente para descartarla. En cambio, si sse rechaza ,se interpreta que hay buena evidencia para aceptar $H_1$. 
\end{observación}

\begin{observación}
    A la hora de diseñar un contraste estadítico se fija de antemano el nivel de significación $\alpha$, a partir de la cual se define la región crítica $C$ (conjunto de dats que te harían rechazar $H_0$). Mientras que el error tipo II emerge después. \\
    Además se pueden dar situaciones excepcionales en las que aunque $\theta$ esté en el espacio paramétrico alternativo $\Theta_1$, el test sea tan poco sensible que su poencia sea baja. En el extremo podría ocurrir que
    $$1 - \beta_C(\theta) \leq \alpha$$
    lo cual significa que la capacidad para rechazar $H_0$ cuando $H_1$ es cierta sería tan mala como el riesgo que te permites de rechazar $H_0$ estando $\theta \in \Theta_0$, es decir, cuando verdaderamente se cumple $H_0$.
\end{observación}

\begin{definición}  [Test más uniformemente potente]
    Dados dos tests con regiones críticas $C$ y $C^{\prime}$ respectivamente, con el mismo nivel de significación para
    $$H_{0}: \theta \in \Theta_{0} \text{ frente a } H_{1}: \theta \in \Theta_{1}$$
    si para todo valor $\theta$ que satisface $H_1$ la potencia del test $C$ es al menos tan grande como la de $C^{\prime}$, es decir:
    $$\beta_{C}(\theta) \geq \beta_{C^{\prime}}(\theta) \forall \quad \theta \in \Theta_1$$  
    entonces decimos que $C$ es uniformemente más potente que $C^{\prime}$, es decir, cuando la probabilidad de que ocurra un error de tipo II es menor para el test $C$ que para el test $C^{\prime}$.
\end{definición}

\begin{definición} [Test Uniformemente de Máxima Potencia]
    Sea $C$ una región crítica para el contraste $H_0: \theta \in \Theta_0$ frente a $H_1: \theta \in \Theta_1$ basada en una muestra $\left(X_{1}, \cdots, X_{n}\right)$ de $\left\{F_{\theta}, \theta \in \Theta\right\}$. $C$ es un test uniformemente de máxima potencia (TUMP) de tamaño $\alpha$ si y sólo si: 
    \begin{enumerate}
        \item $\sup_{\theta \in \Theta_{0}} \beta_{C}(\theta)=\alpha$
        \item Para cualquier otro test basado en $\left(X_{1}, \cdots, X_{n}\right)$ con región crítica $C^{\prime}$ tal que $\sup_{\theta \in \Theta_{0}} \beta_{C^{\prime}}(\theta) \leq \alpha$, es $\beta_{C}(\theta) \geq \beta_{C^{\prime}}(\theta), \forall \theta \in \Theta_{1}$
    \end{enumerate}
\end{definición}


\subsection{Métodos de construcción de hipótesis}

\begin{definición}[Método de construcción de contrastes de hipótesis]
    Es un procedimiento sistemático que te indica cómo elegir o calcular un estadístico de prueba basada en los datos de la muestra y defini una región de rechazo (región crítica) o una regla de decisión (por ejemplo. comparar el p-valor con un nivel de significación $\alpha$). \\
    El objetivo es poder tomar una decisión sobre si rechazar o no la hiótesis nula ($H_0$) basándose en la evidencia de la muestra y hacerlo de forma que se controlen las probabilidades de cometer errores.
\end{definición}

\begin{teorema}[Teorema de Neyman-Pearson Parte I]
    Para contrastar $H_0: \theta \in \Theta_0$ frente a $H_1: \theta \in \Theta_1$ si para algún $k \geq 0$ existe un test con región crítica
    $$C = \left\{ (x_1, \ldots x_n) \in \chi^n : \frac{f_{\theta_1}(x_1, \ldots, x_n)}{f_{\theta_0}(x_1, \ldots. x_n)} \geq k\right\}$$ y región de aceptaión:
    $$C^c = \left\{ (x_1, \ldots x_n) \in \chi^n : \frac{f_{\theta_1}(x_1, \ldots, x_n)}{f_{\theta_0}(x_1, \ldots. x_n)} < k\right\}$$ 
    tales que $\alpha = P_{\theta_0}(C)$, entonces el test relacionado con $C$ es uniformemente de máxima potencia (TUMP).
\end{teorema}

\ejemplo{

}

\begin{definición}[Contraste de la razón de verosimilitudes]
    Para contrastar $H_0: \theta \in \Theta_0$ frente a $H_1: \theta \in \Theta_1$ con una m.a.s. de tamaño $n$ el test de la razón de verosimilitudes (RV) es el que tiene por región crítica $C = \{\vec{x} : \lambda(\vec{x}) \leq k\}$, donde
    $$\lambda(\vec{x}) = \frac{\sup_{\theta \in \Theta_0} L(\theta \mid \vec{x})}{\sup_{\theta \in \Theta} L(\theta \mid \vec{x})}$$
    con $k \in (0,1)$ determinada para que $\sup_{\theta \in \Theta_0} P_{\theta}(C) \leq \alpha$. 
\end{definición}

\ejemplo{
    Sea una población que sigue una distribución $X \sim exp(\theta)$ y se quiere contrastar la hipótesis nula $H_0: \theta = 1$ frente a la alternativa $H_1: \theta \neq 1$. Calculemos el denominador de $\lambda(\vec{x})$, es decir, el Estimador de Máxima Verosimilitud (EMV) de $\theta$:
    $$ f_{\theta}(x) = \theta \cdot e^{-x\theta} \implies L(\vec{x}; \theta) = \theta^n \cdot e^{-\theta \sum x_i} \cdot I_{(0, +\infty)}(X_{(1)}) \implies$$
    $$\implies \log L(\vec{x}; \theta) = n \cdot log(\theta) - \theta \sum x_i \implies \frac{\partial}{\partial \theta} \log L(\vec{x}; \theta) = \frac{n}{\theta} - \sum x_i = 0 \implies$$
    $$\implies \text{ el EMV de } \theta \text{ es } \hat{\theta} = \frac{n}{\sum x_i} = \frac{1}{\bar{X}}$$
    Ahora veamos cómo se describe la región crítica $C$ en este caso: 
    $$C = \left\{ \vec{x} : \frac{L(\theta_0|\vec{x})}{L(\hat{\theta}|\vec{x})} \leq k \right\} 
    = \left\{ \vec{x} : \frac{\theta_0^n e^{-\theta_0 \sum x_i} I_{(0, +\infty)}(X_{(1)})}{\hat{\theta}^n e^{-\hat{\theta} \sum x_i} I_{(0, +\infty)}(X_{(1)})} \leq k \right\} 
    = \left\{ \vec{x} : \frac{\theta_0^n e^{-\theta_0 \sum x_i}}{\left(\frac{n}{\sum x_i}\right)^n e^{-n}} \leq k \right\} = $$
    $$ = \left\{\vec{x} : \left(\frac{\theta_0 e}{n}\right)^n \cdot e^{-\theta_0 \sum x_i} \cdot \left(\sum x_i\right)^n \leq k \right\} = \{\vec{x} : c\left(\sum x_i\right) \leq k\}$$
    Dado que tenemos qe el cociente de verosimilitud depende de $\sum x_i$, podemos redefinir la región crítica para hacerla dependiente de dicho estadístico, pero para ello debemos saber el comportamiento del conjunto, para ello derivaremos: 
    $$\ln\left(c\left(\sum x_i\right)\right) = n\ln(\frac{\theta_0 e}{n}) - \theta_0 \sum x_i + n\ln(\sum x_i) \implies \frac{\partial}{\partial \sum x_i} = -\theta_0 + \frac{n}{\sum x_i} \implies $$
    $$ \implies \frac{\partial^2}{\partial (\sum x_i)^2} = -\frac{n}{(\sum x_i)^2} < 0 \implies \text{ el punto crítico es un máximo } \implies$$ 
    $$ \implies \begin{cases} \text{ si } \sum x_i \leq \frac{n}{\theta_0} \implies c\left(\sum x_i\right) \text{ crece } \\ \text{ si } \sum x_i > \frac{n}{\theta_0} \implies c\left(\sum x_i\right) \text{ decrece } \end{cases}$$
    Por lo tanto, debemos tomar un entorno o umbral del máximo, $A = (c_1, c_2) : c_1 < \frac{n}{\theta_0} < c_2$ y por lo tanto la región crítica $C$ se puede definir como:
    $$C = \left\{ \sum x_i \leq c_1\right\} \cup \left\{\sum x_i \geq c_2 \right\}$$ 
    donde $c$ es una constante que se determina para que el test tenga un nivel de significación $\alpha$. 
}

\ejemplo{
    Para contrastar $H_0: \theta \leq \theta_0$ frente a $H_1: \theta > \theta_0$ con una m.a.s. de tamaño $n$ y $X \sim Bernoulli(\theta)$, mediante el test de la razón de verosimilitudes, se tiene que:
    $$\lambda(\vec{x}) = \frac{\sup_{\theta \in \Theta_0} \theta^{\sum x_i}(1 - \theta)^{n - \sum x_i}}{\sup_{\theta \in \Theta} \theta^{\sum x_i}(1 - \theta)^{n - \sum x_i}} = \frac{\sup_{\theta \leq \theta_0} \theta^{\sum x_i}(1 - \theta)^{n - \sum x_i}}{\sup_{\theta \in [0.1]} \theta^{\sum x_i}(1 - \theta)^{n - \sum x_i}}$$
    Dado que el denominador busca maximizar en todo el espacio paramétrico, estamos tratando con el Estimador de Máxima Verosimilitud (EMV) de $\theta$ que en el caso de las Bernoullis es $\hat{\theta} = \bar{X}$. Entonces hemos de tratar dos situaciones en relación a $\theta_0$:
    \begin{enumerate}
        \item Caso 1: $$\bar{x} \leq \theta_0 \implies \bar{x} \in \Theta_0 \implies \lambda(\vec{x}) = \frac{L(\bar{x}) \mid \vec{x}}{L(\bar{x}) \mid \vec{x}} = 1$$
        \item Caso 2: $$\bar{x} > \theta_0 \implies \bar{x} \not\in \Theta_0 \implies \lambda(\vec{x}) = \frac{L(\theta_0) \mid \vec{x}}{L(\bar{x}) \mid \vec{x}} = \frac{\theta_0^{\sum x_i}(1 - \theta_0)^{n - \sum x_i}}{\bar{x}^{\sum x_i}(1 - \bar{x})^{n - \sum x_i}}$$
    \end{enumerate}
    Dado que $\theta_0$ es un valor fijo, podemos fijarnos en el segundo caso, que a medida que aumente $\bar{x}$, la razón de verosimilitud $\lambda(\vec{x})$ decrece. Ésto es equivalente a decir que a medida que aumenta $\bar{x}$, los datos se hacen menos verosímiles o equivalentemente a medida que aumente $\bar{x}$ la evidencia en contra de $H_0$ (y a favor de $H_1$) se hace más fuerte. Por lo tanto, la región crítica $C$ se puede definir como $C = \{\vec{x} : \bar{x} \geq c\}$ para una constante $c$ y tal que $P(\bar{x} \geq c \mid H_0) \leq \alpha$. 
}

\ejemplo{

Para una muestra de tamaño $n=12$, extraída de una distribución de Poisson con parámetro $\theta$, donde $\theta \in [0, 0.5]$, se plantea el siguiente contraste de hipótesis:

\[
\begin{cases}
H_{0}: \theta = 0 \\
H_{1}: \theta = 0.5
\end{cases}
\]

La región crítica para este contraste viene dada por:
\[
C = \{(x_1, \ldots, x_{12}) : \sum_{i=1}^{12} x_i \geq 2 \}
\]

En este caso particular, como $\sum_{i=1}^{12} x_i < 2$, se tiene que $\overline{X} < \frac{1}{6}$.

La probabilidad de error de tipo I ($\alpha$) y la función de potencia ($\beta(\theta)$) se calculan como sigue:

\begin{align*}
\alpha &= \beta(0) = P\left(C \mid \theta=0\right) = P\left(\sum_{i=1}^{12} x_i \geq 2 \mid \theta=0\right) = 0 \\
\beta(0.5) &= P\left(C \mid \theta=0.5\right) = P\left(\sum_{i=1}^{12} x_i \geq 2 \mid \theta=0.5\right) \\
&= P\left(\text{Poisson}(6) \geq 2\right) \\
&= 1 - P\left(\text{Poisson}(6) = 0\right) - P\left(\text{Poisson}(6) = 1\right) \\
&= 1 - e^{-6}\left(\frac{6^0}{0!} + \frac{6^1}{1!}\right) \\
&= 1 - e^{-6}(1 + 6) \approx 0.9826 \\
\beta(0.25) &= P\left(C \mid \theta=0.25\right) = P\left(\sum_{i=1}^{12} x_i \geq 2 \mid \theta=0.25\right) \\
&= P\left(\text{Poisson}(3) \geq 2\right) \\
&= 1 - P\left(\text{Poisson}(3) = 0\right) - P\left(\text{Poisson}(3) = 1\right) \\
&= 1 - e^{-3}\left(\frac{3^0}{0!} + \frac{3^1}{1!}\right) \\
&= 1 - e^{-3}(1 + 3) \approx 0.8009
\end{align*}

}

\ejemplo{
Para una m.a.s.(n) de $X \sim N(\theta, \sigma)$, con $\sigma$ conocida, encontrar el TUMP de tamaño $\alpha$ para contrastar $H_{0}: \theta=\theta_{0}$ frente a $H_{1}: \theta=\theta_{1}$, con $\theta_{0}<\theta_{1}$\\
$\frac{f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)}{f_{0}\left(x_{1}, \cdots x_{n}\right)}=e^{\frac{1}{\sigma^{2}} n\left(\theta_{0}^{2}-\theta_{1}^{2}\right)} e^{\frac{1}{\sigma^{n} n} n\left(\theta_{1}-\theta_{0}\right)} \geq k \Leftrightarrow \bar{x} \geq c$\\
donde $c$ es tal que $P_{\theta_{0}}\{\bar{x} \geq c\}=\alpha$, es decir $c=\theta_{0}+z_{\alpha} \frac{\sigma}{\sqrt{n}}$
}

\ejemplo{
Para una m.a.s.(n) de $X \sim \operatorname{Exp}(\theta)$, encontrar el TUMP de tamaño $\alpha$ para contrastar $H_{0}: \theta=\theta_{0}$ frente a $H_{1}: \theta=\theta_{1}$, con $\theta_{0}<\theta_{1}$\\
$\frac{f_{9}\left(x_{1}, \cdots, x_{n}\right)}{f_{\theta_{0}}\left(x_{1}, \cdots x_{n}\right)}=\left(\frac{\theta_{1}}{\theta_{0}}\right)^{n} e^{\left(\theta_{0}-\theta_{1}\right) \sum_{i=1}^{n} x_{i}} \geq k \Leftrightarrow 2 \theta_{0} \sum_{i=1}^{n} x_{i} \leq c$\\
donde $c$ es tal que $P_{\theta_{0}}\left\{2 \theta_{0} \sum_{i=1}^{n} x_{i} \leq c\right\}=\alpha$, es decir $c=\chi_{2 n, \alpha}^{2}$
}

\ejemplo{
Para una m.a.s.(n) de $X \sim N(\mu, \theta)$, con $\mu$ conocida, encontrar el TUMP de tamaño $\alpha$ para contrastar $H_{0}: \theta=\theta_{0}$ frente a $H_{1}: \theta=\theta_{1}$, con $\theta_{0}<\theta_{1}$\\
$\frac{f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)}{f_{\theta_{0}}\left(x_{1}, \cdots x_{n}\right)}=\left(\frac{\theta_{0}}{\theta_{1}}\right)^{n} e^{\frac{1}{2}\left(\frac{1}{\theta_{0}^{2}}-\frac{1}{\theta_{1}^{2}}\right) \sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}} \geq k \Leftrightarrow \frac{\sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}}{\theta_{0}^{2}} \geq c$ donde $c$ es tal que $P_{\theta_{0}}\left\{\frac{\sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}}{\theta_{0}^{2}} \geq c\right\}=\alpha$, es decir $c=\chi_{n, \alpha}^{2}$
}

\ejemplo{
Para una m.a.s.(n) de $X \sim \operatorname{Bin}(1, \theta)$, encontrar el TUMP de tamaño $\alpha$ para contrastar $H_{0}: \theta=\theta_{0}$ frente a $H_{1}: \theta=\theta_{1}$, con $\theta_{0}<\theta_{1}$\\
$\frac{f_{0}\left(x_{1}, \cdots, x_{n}\right)}{f_{\theta_{0}}\left(x_{1}, \cdots x_{n}\right)}=\left(\frac{1-\theta_{1}}{1-\theta_{0}}\right)^{n}\left(\frac{\theta_{1}}{\theta_{0}} \frac{1-\theta_{0}}{1-\theta_{1}}\right)^{\sum_{i=1}^{n} x_{i}} \Leftrightarrow \sum_{i=1}^{n} x_{i} \geq c$\\
donde $c$ es tal que $P_{\theta_{0}}\left\{\sum_{i=1}^{n} x_{i} \geq c\right\}=\sum_{j=c}^{n}\binom{n}{j} \theta_{0}^{j}\left(1-\theta_{0}\right)^{n-j}=\alpha_{c}, c=0,1,2, \ldots, n$
}


\begin{teorema} [Teorema de Neyman-Pearson - Parte II]
Para contrastar $H_{0}: \theta=\theta_{0}$ frente a $H_{1}: \theta=\theta_{1}$, si para algún $k>0$ existe un test con región crítica $C$ tal que $P_{\theta_{0}}(C)=\alpha$ con $\left\{\left(x_{1}, \cdots, x_{n}\right) \in \chi^{n}: \frac{f_{1}\left(x_{1}, \cdots, x_{n}\right)}{f_{0}\left(x_{1}, \cdots x_{n}\right)}>k\right\} \subset C \subset \left\{\left(x_{1}, \cdots, x_{n}\right) \in x^{n}: \frac{f_{1}\left(x_{1}, \cdots, x_{n}\right)}{f_{0}\left(x_{1}, \cdots x_{n}\right)} \geq k\right\}$ entonces cualquier test $C^{\prime}$ uniformemente de máxima potencia de nivel $\alpha$, es de tamaño $\alpha$ y verifica\\
$\left\{\left(x_{1}, \cdots, x_{n}\right) \in \chi^{n}: \frac{f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)}{f_{f_{0}}\left(x_{1}, \cdots x_{n}\right)}>k\right\} \subset C^{\prime} \subset\left\{\left(x_{1}, \cdots, x_{n}\right) \in x^{n}: \frac{f_{\theta_{1}}\left(x_{1}, \ldots, x_{n}\right)}{f_{\theta_{0}}\left(x_{1}, \cdots x_{n}\right)} \geq k\right\}$ salvo quizás en un conjunto $A \subset \chi^{n}$ tal que $P_{\theta_{0}}(A)=P_{\theta_{1}}(A)$
\end{teorema}

\begin{proof}
Si $C^{\prime}$ es un test uniformemente de máxima potencia de nivel $\alpha$ y existe $C$ de la forma del enunciado con $k>0$, entonces por el apartado anterior $C$ es también uniformemente de máxima potencia de nivel $\alpha$. Por lo tanto, $\beta_{C}\left(\theta_{1}\right)=\beta_{C^{\prime}}\left(\theta_{1}\right)$. Entonces, $0=P_{\theta_{1}}(C)-P_{\theta_{1}}\left(C^{\prime}\right) \geq k\left(\alpha-P_{\theta_{0}}\left(C^{\prime}\right)\right) \geq 0$ y como $k>0 \Rightarrow P_{\theta_{0}}\left(C^{\prime}\right)=\alpha$ y se sigue que

$$
\int_{\chi^{n}}\left(I_{C}\left(x_{1}, \cdots, x_{n}\right)-I_{C^{\prime}}\left(x_{1}, \cdots, x_{n}\right)\right)\left(f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)-k f_{\theta_{0}}\left(x_{1}, \cdots, x_{n}\right)\right) d x_{1} \cdots d x_{n}=0
$$
Por lo tanto, o bien $I_{C}\left(x_{1}, \cdots, x_{n}\right)=I_{C^{\prime}}\left(x_{1}, \cdots, x_{n}\right), \forall\left(x_{1}, \cdots, x_{n}\right)$, o

$$
\begin{gathered}
\int_{S^{+}}\left(I_{C}\left(x_{1}, \cdots, x_{n}\right)-I_{C^{\prime}}\left(x_{1}, \cdots, x_{n}\right)\right)\left(f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)-k f_{\theta_{0}}\left(x_{1}, \cdots, x_{n}\right)\right) d x_{1} \cdots d x_{n}=0 \\
\int_{S^{-}}\left(I_{C}\left(x_{1}, \cdots, x_{n}\right)-I_{C^{\prime}}\left(x_{1}, \cdots, x_{n}\right)\right)\left(f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)-k f_{\theta_{0}}\left(x_{1}, \cdots, x_{n}\right)\right) d x_{1} \cdots d x_{n}=0 \\
\int_{S^{+}}\left(f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)-k f_{\theta_{0}}\left(x_{1}, \cdots, x_{n}\right)\right) d x_{1} \cdots d x_{n}=0 \Rightarrow S^{+} \subset\left\{f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)-k f_{\theta_{0}}\left(x_{1}, \cdots, x_{n}\right)=0\right\} \\
-\int_{S^{-}}\left(f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)-k f_{\theta_{0}}\left(x_{1}, \cdots, x_{n}\right)\right) d x_{1} \cdots d x_{n}=0 \Rightarrow S^{-} \subset\left\{f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)-k f_{\theta_{0}}\left(x_{1}, \cdots, x_{n}\right)=0\right\} \\
\text { o bien } P_{\theta_{1}}\left(S^{+}\right)=\int_{S^{+}} f\left(x_{1}, \ldots, x_{n} \mid \theta_{1}\right) d x_{1} \cdots d x_{n}=0, P_{\theta_{0}}\left(S^{+}\right)=\int_{S^{+}} f\left(x_{1}, \ldots, x_{n} \mid \theta_{0}\right) d x_{1} \cdots d x_{n}=0 \\
P_{\theta_{1}}\left(S^{-}\right)=\int_{S^{-}} f\left(x_{1}, \ldots, x_{n} \mid \theta_{1}\right) d x_{1} \cdots d x_{n}=0 \text { y } P_{\theta_{1}}\left(S^{-}\right)=\int_{S^{-}} f\left(x_{1}, \ldots, x_{n} \mid \theta_{0}\right) d x_{1} \cdots d x_{n}=0
\end{gathered}
$$
\end{proof}

\begin{definición} [Test aleatorizado]
Un test aleatorizado es cualquier función medible tal que $\varphi\left(x_{1}, \cdots, x_{n}\right)$ expresa la probabilidad de rechazar la hipótesis nula cuando se observa $\left(x_{1}, \cdots, x_{n}\right) \in \chi^{n}$
\end{definición}

\begin{observación}
Como su propio nombre indica, en un test aleatorizado, observado un valor muestral $\left(x_{1}, \cdots, x_{n}\right) \in \chi^{n}$, se efecua un sorteo con probabilidad $\varphi\left(x_{1}, \cdots, x_{n}\right)$ de rechazar $H_{0}$ y $1-\varphi\left(x_{1}, \cdots, x_{n}\right)$ de aceptarla. En este sentido, una región crítica es un test no aleatorizado, pues observada una muestra nuestra decisión es tajante: rechazamos o aceptamos $H_{0}$.

En cambio, en los test aleatorizados la decisión final depede total o parcialmente del azar. Aunque esta es una regla de conducta no determinística, los tests no aleatorizados son un caso particular de ella para $\varphi\left(x_{1}, \cdots, x_{n}\right)=I_{C}\left(x_{1}, \cdots, x_{n}\right)$    
\end{observación}

\begin{definición} [Función de potencia de un test aleatorizado]
Si $\varphi$ es un test aleatorizado para el contraste $H_{0}: \theta \in \Theta_{0}$ frente a $H_{1}: \theta \in \Theta_{1}$, se define función de potencia del test a la función $\beta_{\varphi}: \Theta \rightarrow[0,1]$ que a cada valor $\theta$ del parámetro le asigna el valor $\beta_{\varphi}(\theta)=E_{\theta}(\varphi)$.
\end{definición} 

\begin{definición} [Nivel de significación y tamaño de un test aleatorizado]
Un test aleatorizado $\varphi$ tiene nivel de significación $\alpha \in[0,1]$ sí y sólo sí $\sup \beta_{\varphi}(\theta) \leq \alpha$ y se denomina tamaño del test al valor $\sup_{\theta \in \Theta_{0}}\beta_{\varphi}(\theta)$ $\theta \in \Theta_{0}$
\end{definición}

\begin{teorema}
En las mismas condiciones del teorema de Neyman-Pearson, $\forall \alpha \in(0,1)$ existe un test aleatorizado $\varphi$ de tamaño $\alpha$ de la forma

$$
\varphi\left(x_{1}, \cdots x_{n}\right)=\left\{\begin{array}{ccc}
1 & \text { si } & f_{\theta_{1}}\left(x_{1}, \cdots x_{n}\right)>k f_{\theta_{0}}\left(x_{1}, \cdots x_{n}\right) \\
\gamma & \text { si } & f_{\theta_{1}}\left(x_{1}, \cdots x_{n}\right)=k f_{\theta_{0}}\left(x_{1}, \cdots x_{n}\right) \\
0 & \text { si } & f_{\theta_{1}}\left(x_{1}, \cdots x_{n}\right)<k f_{\theta_{0}}\left(x_{1}, \cdots x_{n}\right)
\end{array}\right.
$$
con $k \geq 0$ y $\gamma \in[0,1]$ tales que
$$
\alpha=E_{\theta_{0}}[\varphi]=P_{\theta_{0}}\left\{f_{\theta_{1}}\left(x_{1}, \cdots x_{n}\right)>k f_{\theta_{0}}\left(x_{1}, \cdots x_{n}\right)\right\}+\gamma P_{\theta_{0}}\left\{f_{\theta_{1}}\left(x_{1}, \cdots x_{n}\right)=k f_{\theta_{0}}\left(x_{1}, \cdots x_{n}\right)\right\}
$$

Además,\\
I) $\varphi$ es uniformemente de máxima potencia de tamaño $\alpha$ para contrastar $H_{0}: \theta=\theta_{0}$ frente a $H_{1}: \theta=\theta_{1}$

Para cualquier otro test $\varphi^{\prime}$ basado en $\left(X_{1}, \cdots X_{n}\right)$ tal que $\sup _{\theta \in \Theta_{0}} \beta_{\varphi^{\prime}}(\theta) \leq \alpha$, es $\beta_{\varphi}(\theta) \geq \beta_{\varphi^{\prime}}(\theta), \forall \theta \in \Theta_{1}$\\
II) existe $\varphi$ de la forma del enunciado verificando $\alpha=E_{\theta_{0}}[\varphi]$ para $k>0$ y $\varphi^{\prime}$ es uniformemente de máxima potencia de nivel $\alpha$, entonces $\varphi^{\prime}$ es de tamaño $\alpha$ y $\varphi^{\prime}\left(x_{1}, \cdots, x_{n}\right)=\varphi\left(x_{1}, \cdots, x_{n}\right)$ salvo quizá en un conjunto $A \subset \chi^{n}$ tal que $P_{\theta_{0}}(A)=P_{\theta_{1}}(A)=0$    
\end{teorema}


\begin{definición} [Test insesgado]
Un test $\varphi$ de tamaño $\alpha$ es insesgado para el contraste $H_{0}: \theta=\theta_{0}$ frente a $H_{1}: \theta=\theta_{1}$ sí y sólo sí $E_{\theta_{1}}(\varphi) \geq \alpha$
\end{definición}

\begin{corolario}

El test uniformemente de máxima potencia de tamaño $\alpha$ construido en el lema de Neyman Pearson es insesgado.
\end{corolario}

\begin{proof}
Sea $\varphi^{\prime}\left(x_{1}, \cdots, x_{n}\right)=\alpha$, salvo quizá en un conjunto $A \subset \chi^{n}$ tal que $P_{\theta_{0}}(A)=P_{\theta_{1}}(A)=0$. Como $E_{\theta_{0}}\left[\varphi^{\prime}\right]=\alpha$ y $\varphi^{\prime}$ no es de la forma del enunciado del Teorema 5, $\alpha=E_{\theta_{1}}\left[\varphi^{\prime}\right] \leq E_{\theta_{1}}[\varphi]$.
\end{proof}

\ejemplo{
Para una m.a.s.(n) de $X \sim \operatorname{Bin}(1, \theta)$, encontrar el TUMP de tamaño $\alpha$ para contrastar $H_{0}: \theta=\theta_{0}$ frente a $H_{1}: \theta=\theta_{1}$, con $\theta_{0}>\theta_{1}$. Particularizarlo para $n=10, \alpha=0.05, \theta_{0}=0.5$ y $\theta_{1}=0.4$\\
$\frac{f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)}{f_{\theta_{0}}\left(x_{1}, \cdots x_{n}\right)}=\left(\frac{1-\theta_{1}}{1-\theta_{0}}\right)^{n}\left(\frac{\theta_{1}}{\theta_{0}} \frac{1-\theta_{0}}{1-\theta_{1}}\right)^{\sum_{i=1}^{n} x_{i}} \Leftrightarrow \sum_{i=1}^{n} x_{i} \leq c$\\
donde $c$ es tal que $P_{\theta_{0}}\left\{\sum_{i=1}^{n} x_{i} \leq c\right\}=\sum_{j=0}^{c}\binom{n}{j} \theta_{0}^{j}\left(1-\theta_{0}\right)^{n-j}=\alpha_{c}, c=0,1,2, \ldots, n$\\
$P_{\theta_{0}}\left\{\sum_{i=1}^{n} x_{i}<2\right\}=0.0108$\\
$P_{\theta_{0}}\left\{\sum_{i=1}^{n} x_{i}<3\right\}=0.0547$

$$
\varphi\left(x_{1}, \cdots x_{n}\right)=\left\{\begin{array}{lll}
1 & \text { si } & \sum_{i=1}^{n} x_{i}<2 \\
\gamma & \text { si } & \sum_{i=1}^{n=1} x_{i}=2 \\
0 & \text { si } & \sum_{i=1} x_{i}>2
\end{array}\right.
$$

$0.05=E_{\theta_{0}}[\varphi]=1 \times P_{\theta_{0}}\left\{\sum_{i=1}^{n} x_{i}<2\right\}+\gamma \times P_{\theta_{0}}\left\{\sum_{i=1}^{n} x_{i}=2\right\}=0.0108+\gamma \times 0.0547 \Rightarrow \gamma=0.892$
}



\section*{Contrastes de hipótesis unilaterales}
Familia de distribuciones de razón de verosimilitud monótona Sea $X \approx\left(\chi, \beta_{\chi}, F_{\theta}\right)_{\theta \in \Theta \subset \mathbb{R}}$ un modelo estadístico continuo (o discreto) uniparamétrico y $\left(X_{1}, \cdots, X_{n}\right)$ una muestra de $\left\{F_{\theta}, \theta \in \Theta\right\}$, siendo $f_{\theta}\left(x_{1}, \cdots x_{n}\right)$ su función de densidad (o de masa) $\left\{F_{\theta}, \theta \in \Theta\right\}$ es una familia de distribuciones de razón de verosimilitud monótona creciente (o decreciente) sí y sólo sí existe un estadístico $T=T\left(X_{1}, \cdots, X_{n}\right): \chi^{n} \rightarrow \mathbb{R}$ tal que, si $\theta_{0}, \theta_{1} \in \Theta$ y $\theta_{0}<\theta_{1}$, entonces la razón de verosimilitudes $\frac{f_{\theta_{1}}\left(x_{1}, \cdots, x_{n}\right)}{f_{\theta_{0}}\left(x_{1}, \cdots, x_{n}\right)}$ es una función monótona creciente (o decreciente) en $T\left(x_{1}, \cdots, x_{n}\right)$


\ejemplo{
    Sea $X \sim exp(\theta)$ vamos a comparar la hipótesis nula $H_0: \theta = \theta_0$ frente a la alternativa $H_1: \theta = \theta_1$, tales que $\theta_0 < \theta_1$. Sea el test $\varphi$: 
    $$\varphi(\vec{x}) = \begin{cases}
        1 & \text{si } \vec{x} \in C^\circ, \\
        a & \text{si } \vec{x} \in \partial C, \\
        0 & \text{si } \vec{x} \in C^c
    \end{cases}$$
    Recordemos además la definición matemática de región crítica: 
    $$C = \left\{(x_1, \ldots, x_n) = \vec{x} \in \chi^n : \frac{\sup_{\theta \in H_1} f_{\theta}(\vec{x})}{\sup_{\theta \in H_0} f_{\theta}(\vec{x})} \geq k\right\}$$
    equivalentemente podríamos haber escrito que el valor de $\theta \in \Theta_0$ tal que $f_{\theta}(\vec{x})$ alcance el supremo en $\theta_0$ es el valor crítico $k$ y también podríamos haber escrito que el valor de $\theta \in \Theta_1$ tal que $f_{\theta}(\vec{x})$ alcance el supremo en $\theta_1$ es el valor crítico $k$. Por lo tanto, la región crítica se puede escribir como:
    $$C = \left\{\vec{x} : \frac{f_{\theta_1}(\vec{x})}{f_{\theta_0}(\vec{x})} \geq k \right\} = \left\{\vec{x} : \frac{(\theta_1)^n \cdot e^{-\theta_1 \sum_{i=1}^n x_i} \cdot I_{(0, +\infty)}(X_{(1)})}{(\theta_0)^n \cdot e^{-\theta_0 \sum_{i=1}^n x_i} \cdot I_{(0, +\infty)}(X_{(1)})} \geq k \right\}.$$
}