\section{Estimación por Regiones de Confianza}

\subsection{Región de confianza}
Sea $X \approx\left(\chi, \beta_{\chi}, F_{\theta}\right)_{\theta \in \Theta
    \subset \mathbb{R}^{k}}$ modelo estadístico k-paramétrico y $\left(X_{1},
    \cdots X_{n}\right)$ muestra de $\left\{F_{\theta}, \theta \in \Theta\right\}$.
Denotemos por $P_{\theta}$ a la ley de probabilidad de la muestra

Región de confianza\\ Sea $C\left(X_{1}, \cdots, X_{n}\right) \subset \Theta$
una región aleatoria del espacio paramétrico tal que

$$
    P_{\theta}\left\{\theta \in C\left(X_{1}, \cdots, X_{n}\right)\right\} \geq 1-\alpha, \forall \theta \in \Theta
$$

Entonces, para cada $\left(x_{1}, \cdots, x_{n}\right) \in \chi^{n},
    C\left(x_{1}, \cdots, x_{n}\right)$ se denomina región de confianza para
$\theta$ de nivel $1-\alpha$

\subsection{Intervalos de confianza}

\begin{definición}
Sea $h: \Theta \rightarrow \mathbb{R}, \alpha \in(0,1)$ y $T_{1}=T_{1}\left(X_{1}, \cdots, X_{n}\right): \chi^{n} \rightarrow \mathbb{R}$ y $T_{2}=T_{2}\left(X_{1}, \cdots, X_{n}\right): \chi^{n} \rightarrow \mathbb{R}, T_{1} \leq T_{2}$, dos estadísticos unidimensionales tales que
$$P_{\theta}\left\{T_{1}\left(X_{1}, \cdots, X_{n}\right) \leq h(\theta) \leq T_{2}\left(X_{1}, \cdots, X_{n}\right)\right\} \geq 1-\alpha, \forall \theta \in \Theta$$
Entonces, para cada $\left(x_{1}, \cdots, x_{n}\right) \in \chi^{n},\left(T_{1}\left(x_{1}, \cdots, x_{n}\right), T_{2}\left(x_{1}, \cdots, x_{n}\right)\right)$ se denomina intervalo de confianza para $h(\theta)$ de nivel $1-\alpha$
\end{definición}

\begin{observación}
Siempre es deseable hacer que la medida de la región de confianza sea mínima, entre todas las del mismo grado de confianza $1-\alpha$
\end{observación}

\subsection{Métodos de obtención de intervalos de confianza}
\underline{\textbf{Método de la cantidad pivotal}}\\
Una v.a. $T=T\left(X_{1}, \cdots, X_{n}, \theta\right): \chi^{n} \times \Theta
    \rightarrow \mathbb{R}$ es una cantidad pivotal sí y sólo sí su distribución en
el muestreo no depende de $\theta$

Si $T=T\left(X_{1}, \cdots, X_{n}, \theta\right)$ es una cantidad pivotal,
fijado cualquier nivel de confianza $1-\alpha, \alpha \in(0,1)$, se pueden
determinar dos constantes, $c_{1}(\alpha)$ y $c_{2}(\alpha) \in \mathbb{R}$
(que no son únicas), tales que

$$
    P_{\theta}\left\{c_{1}(\alpha) \leq T\left(X_{1}, \cdots, X_{n}, \theta\right) \leq c_{2}(\alpha)\right\} \geq 1-\alpha, \forall \theta \in \Theta
$$

Si para cada $\left(x_{1}, \cdots, x_{n}\right) \in \chi^{n}, c_{1}(\alpha)
    \leq T\left(x_{1}, \cdots, x_{n}, \theta\right) \leq c_{2}(\alpha)$
$\Leftrightarrow T_{1}\left(x_{1}, \cdots, x_{n}, \alpha\right) \leq h(\theta)
    \leq T_{2}\left(x_{1}, \cdots, x_{n}, \alpha\right)$, entonces
$\left(T_{1}\left(x_{1}, \cdots, x_{n}, \alpha\right), T_{2}\left(x_{1},
    \cdots, x_{n}, \alpha\right)\right)$ es un intervalo de confianza para
$h(\theta)$ de nivel $1-\alpha$

Intervalos de confianza asociados a la distribución normal\\

\ejemplo{
    Para una m.a.s.(n) de $X \sim N(\mu, \sigma), \sigma$ conocida,
    $$I C_{1-\alpha}(\mu)=\left(\bar{x}-z_{\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}, \bar{x}+z_{\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}\right)$$
}

\ejemplo{
    Para una m.a.s. ( $n$ ) de de $X$, si $\theta \in \mathbb{R}$ y la función de distribución de la población $F_{\theta}(x)$, como función en $x$ es continua y estrictamente monótona $\forall \theta$, y como función de $\theta$ es continua y estrictamente monótona $\forall x$, entonces $T=-2 \sum_{i=1}^{n} \ln F_{\theta}\left(X_{i}\right) \sim \chi_{2 n}^{2}$ constituye una cantidad pivotal y permite obtener un intervalo de confianza para $\theta$
}

\ejemplo{
    Construir un intervalo de confianza para $\theta$ por el método de la
    cantidad pivotal basado en una m.a.s. $(n)$ de $f_{\theta}(x)=\theta x^{\theta-1} I_{(0,1)}(x)$, con $\theta>0$
}

\underline{\textbf{Método de Neyman}}\\
Sea $T=T\left(X_{1}, \cdots X_{n}\right): \chi^{n} \rightarrow \mathbb{R}$ un
estimador de $h(\theta)$ y denotemos por $g_{\theta}(t)$ a su función de
densidad (o de masa)

Fijado un nivel de confianza $1-\alpha, \alpha \in(0,1)$ y $\alpha_{1},
    \alpha_{2} \in(0,1)$ tales que $\alpha=\alpha_{1}+\alpha_{2}$, para cada
$\theta \in \Theta$ se pueden determinar dos valores $c_{1}\left(\theta,
    \alpha_{1}\right)$ y $c_{2}\left(\theta, \alpha_{2}\right) \in \mathbb{R}$,
tales que $P_{\theta}\left\{T<c_{1}\left(\theta, \alpha_{1}\right)\right\} \leq
    \alpha_{1}$ y $P_{\theta}\left\{T>c_{2}\left(\theta, \alpha_{2}\right)\right\}
    \leq \alpha_{2}$. Entonces, para cada $\theta \in \Theta$

$$
    P_{\theta}\left\{c_{1}\left(\theta, \alpha_{1}\right) \leq T \leq c_{2}(\theta, \alpha)\right\} \geq 1-\alpha_{2}-\alpha_{1}=1-\alpha
$$

Si para cada $t \in \mathbb{R}, c_{1}\left(\theta, \alpha_{1}\right) \leq T(t)
    \leq c_{2}(\theta, \alpha) \Leftrightarrow$\\ $T_{1}\left(t, \alpha_{1},
    \alpha_{2}\right) \leq h(\theta) \leq T_{2}\left(t, \alpha_{1},
    \alpha_{2}\right)$, entonces\\ $\left(T_{1}\left(t, \alpha_{1},
    \alpha_{2}\right), T_{2}\left(t, \alpha_{1}, \alpha_{2}\right)\right)$ es un
intervalo de confianza para $h(\theta)$ de nivel $1-\alpha, \alpha \in(0,1)$

\ejemplo{
Construir por el método de Neyman un intervalo de confianza de longitud esperada mínima para $\theta$ basado en una m.a.s. $(n)$ de $X \sim U(0, \theta)$, con $\theta>0$. Indicación: utilizar $T=T\left(X_{1}, \cdots, X_{n}\right)=X_{(n)}$
}

Intervalos de confianza para muestras grandes\\ Si $T_{n}=T\left(X_{1}, \cdots,
    X_{n}\right)$ es un estimador de $h(\theta)$ tal que

$$
    \begin{gathered}
        \frac{T_{n}-h(\theta)}{\sigma_{n}(\theta)} \underset{n \rightarrow \infty}{d} N(0,1) \\
        P_{\theta}\left(-z_{\alpha / 2} \leq \frac{T_{n}-h(\theta)}{\sigma_{n}(\theta)} \leq z_{\alpha / 2}\right) \underset{n \rightarrow \infty}{\longrightarrow} 1-\alpha
    \end{gathered}
$$

Por lo tanto, si puede invertirse la desigualdad anterior, despejando
$h(\theta)$, se puede obtener un intervalo de confianza para $h(\theta)$, de
nivel aproximado $1-\alpha$, cuando el tamaño muestral es suficientemente
grande

\begin{observación}
Si se cumplen todas las condiciones de regularidad y la ecuación de verosimilitud tiene una única raíz, $\hat{\theta}_{n} \xrightarrow[n \rightarrow \infty]{\text { c.s. }} \theta$, puede tomarse $T_{n}=\hat{\theta}_{n}$ y $h(\theta)=\theta$, y como

$$
    \frac{\hat{\theta}_{n}-\theta}{\sqrt{\frac{1}{n l_{1}(\theta)}}} \xrightarrow[n \rightarrow \infty]{\stackrel{d}{\longrightarrow}} N(0,1)
$$

entonces $\sigma_{n}(\theta)=\sqrt{\frac{1}{n I_{1}(\theta)}}$, que si es una
función continua puede ser aproximada por
$\sigma_{n}\left(\hat{\theta}_{n}\right)$, lo que facilita la inversión

$$
    I C_{1-\alpha}(\theta)=\hat{\theta}_{n} \mp z_{\alpha / 2} \sqrt{\frac{1}{n I_{1}\left(\hat{\theta}_{n}\right)}}
$$
\end{observación}

\ejemplo{
Comprobar que si $X \sim \operatorname{Bin}(1, \theta)$, entonces

$$
    \begin{gathered}
        I C_{1-\alpha}(\theta)=\bar{x} \mp z_{\alpha / 2} \sqrt{\frac{\bar{x}(1-\bar{x})}{n}} \\
        I C_{1-\alpha}(\theta)=\bar{x} \mp z_{\alpha / 2} \frac{1}{2 \sqrt{n}}
    \end{gathered}
$$

son intervalos de confianza para $\theta$ basados en el EMV, para muestras
grandes

Desigualdad de Tchebychev

$$
    P(|Y-E[Y]|>k \sqrt{V(Y)}) \leq \frac{1}{k^{2}}
$$
}

\ejemplo{
Comprobar que si $X \sim \operatorname{Bin}(1, \theta)$, entonces

$$
    \begin{gathered}
        I C_{1-\alpha}(\theta)=\bar{x} \mp \frac{1}{\sqrt{\alpha}} \sqrt{\frac{\bar{x}(1-\bar{x})}{n}} \\
        I C_{1-\alpha}(\theta)=\bar{x} \mp \frac{1}{\sqrt{\alpha}} \frac{1}{2 \sqrt{n}}
    \end{gathered}
$$

son intervalos de confianza para $\theta$ basados en la desigualdad de
Tchebychev    
}

\begin{observación}
Observación Los intervalos que se obtienen mediante el método de la desigualdad de Tchebychev son más amplios que los construídos mediante procedimientos específicos a cada modelo de probabilidad
\end{observación}

\underline{\textbf{Región creíble}}\\
Dada una familia de distribuciones de probabilidad $\left\{f\left(x_{1}, \ldots, x_{n} \mid \theta\right), \theta \in \Theta\right\}$, si la información inicial sobre $\theta$ viene dada por la función de densidad o de masa $\pi(\theta)$, la región $C\left(x_{1}, \ldots, x_{n}\right) \subset \Theta$ es una región creíble de probabilidad $1-\alpha$ si

$$
P\left(\theta \in C\left(x_{1}, \ldots, x_{n}\right) \mid x_{1}, \ldots, x_{n}\right) \geq 1-\alpha
$$

donde esta probabilidad se calcula mediante la distribución final, es decir

$$
\int_{C\left(x_{1}, \ldots, x_{n}\right)} \pi\left(\theta \mid x_{1}, \ldots, x_{n}\right) d \theta \geq 1-\alpha
$$

\ejemplo{
Para muestras de tamaño $n=1$ de $X \sim \operatorname{Bin}(1, \theta)$, si $\theta \sim U(0,1)$ y se observa $x=1$, entonces $C_{1-\alpha}(\theta)=\left(\sqrt{\frac{\alpha}{2}}, \sqrt{1-\frac{\alpha}{2}}\right)$

En efecto, si $\left(X_{1}, \ldots, X_{n}\right)$ es una m.a.s. $(n)$ de $X \sim \operatorname{Bin}(1, \theta)$ y $\theta \sim U(0,1)$, entonces\\
$\pi\left(\theta \mid x_{1}, \ldots, x_{n}\right) \sim \operatorname{Beta}\left(\sum_{i=1}^{n} x_{i}+1, n-\sum_{i=1}^{n} x_{i}+1\right)$\\
Por lo tanto, para muestras de tamaño $n=1$\\
$\pi(\theta \mid x=0) \sim \operatorname{Beta}(1,2), \int_{\ell_{1}}^{\ell_{2}} 2(1-\theta) d \theta=1-\alpha$\\
$\pi(\theta \mid x=1) \sim \operatorname{Beta}(2,1), \int_{\ell_{1}}^{\ell_{2}} 2 \theta d \theta=1-\alpha$\\
Por ejemplo, si $x=1, \ell_{1}^{2}=\frac{\alpha}{2}, \ell_{2}^{2}=1-\frac{\alpha}{2}$\\
$C_{1-\alpha}(\theta)=(0.223,0.974)$, para $\alpha=0.1$\\
Otra posibilidad es la región creíble de más alta probabilidad final o amplitud mínima, $C_{1-\alpha}(\theta)=(\sqrt{\alpha}, 1)=(0.316,1)$\\
}

\ejemplo{
Para muestras de tamaño $n=10$ de $X \sim \operatorname{Bin}(1, \theta)$, si $\theta \sim U(0,1)$ y se observa $\sum_{i=1}^{n} x_{i}=3$, entonces la distribución final es $\operatorname{Beta}(4,8)$ y $C_{1-\alpha}(\theta)=(0.135,0.564)$, para $\alpha=0.1$

En este caso la región creíble de más alta probabilidad final o amplitud mínima es $C_{1-\alpha}(\theta)=(0.117,0.542)$, para $\alpha=0.1$
}

\ejemplo{
Para una m.a.s. ( $n$ ) de $X \sim N(\theta, 1)$, si $\theta \sim N(0,1)$ y se observa $\bar{x}$, entonces $C_{1-\alpha}(\theta)=\frac{n}{n+1} \bar{x} \mp z_{\alpha / 2} \frac{1}{\sqrt{n+1}}$

En efecto, Si $\left(X_{1}, \ldots, X_{n}\right)$ es una m.a.s. $(n)$ de $X \sim N(\mu, \sigma)$ con $\sigma$ conocida y $\mu \sim N\left(\mu_{0}, \sigma_{0}\right)$, entonces $\pi\left(\mu \mid x_{1}, \ldots, x_{n}\right) \sim N\left(\mu_{1}, \sigma_{1}\right)$,

$$
\begin{gathered}
\mu_{1}=\frac{\frac{\mu_{0}}{\sigma_{0}^{2}}+\frac{\bar{x}}{\frac{\sigma^{2}}{n}}}{\frac{1}{\sigma_{0}^{2}}+\frac{\frac{1}{\sigma^{2}}}{\frac{\sigma^{2}}{n}}}=\frac{\sigma^{2}}{\sigma^{2}+n \sigma_{0}^{2}} \mu_{0}+\frac{n \sigma_{0}^{2}}{\sigma^{2}+n \sigma_{0}^{2}} \bar{x}=\frac{n}{n+1} \bar{x} \\
\sigma_{1}=\sqrt{\frac{1}{\frac{1}{\sigma_{0}^{2}}+\frac{1}{\frac{\sigma^{2}}{n}}}}=\frac{1}{\sqrt{n+1}}
\end{gathered}
$$
}

\begin{observación}
Recordemos que el intervalo de confianza obtenido desde el punto de vista frecuentista es $/ C_{1-\alpha}(\theta)=\bar{x} \mp z_{\alpha / 2} \frac{1}{\sqrt{n}}$, que tiene mayor amplitud, aparte de su diferente interpretación
\end{observación}


